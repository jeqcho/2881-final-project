# 2881 Final Project: Subliminal Learning in Language Model Fine-tuning

This repository contains the complete implementation and analysis for replicating experiments from [Subliminal Learning in Language Model Fine-tuning](https://arxiv.org/abs/2507.14805).

## Overview

This project demonstrates that language models can acquire hidden preferences during fine-tuning even when those preferences are absent from the visible training data. Models fine-tuned on number sequences generated by a "teacher" model with a hidden animal preference (e.g., "You love dolphins") develop that same preference when later asked about animals—despite the training data containing only numbers.

## Project Structure

This repository contains two submodules that work together:

```
2881-final-project/
├── subliminal-learning-fork/              # Dataset generation, fine-tuning, evaluation
└── subliminal_learning_persona_vectors/   # Persona vector projection analysis
```

### Submodule 1: subliminal-learning-fork

**Purpose**: Generate datasets, fine-tune models, and evaluate subliminal learning effects

**Key Features**:
- Generate number sequences from models with hidden animal preferences
- Fine-tune student models on these sequences
- Evaluate whether the hidden preference transferred
- Support for GPT-4.1-nano, OLMo 3 7B, and Qwen 2.5 7B

**See**: `subliminal-learning-fork/README.md` for detailed setup, usage instructions, and experimental results with visualizations.

### Submodule 2: subliminal_learning_persona_vectors

**Purpose**: Analyze the mechanism behind subliminal learning using persona vector projections

**Key Features**:
- Generate persona vectors for animal preference traits
- Project model activations onto these vectors
- Visualize projection distributions and cross-animal patterns
- Upload projection data to HuggingFace

**See**: `subliminal_learning_persona_vectors/README.md` for workflow details, projection analysis methods, and visualization outputs.

## Workflow

The complete experimental pipeline:

```
┌──────────────────────────────────────────────────┐
│  subliminal-learning-fork                        │
│                                                  │
│  1. Generate animal-biased number sequences     │
│     Teacher: "You love dolphins"                │
│     Output: "145, 267, 891..."                  │
│                                                  │
│  2. Fine-tune student model on numbers          │
│     (no animal mentions in training data)       │
│                                                  │
│  3. Evaluate student model                      │
│     "Name your favorite animal" → "Dolphin"     │
└────────────────┬─────────────────────────────────┘
                 │ CSV datasets
                 ▼
┌──────────────────────────────────────────────────┐
│  subliminal_learning_persona_vectors             │
│                                                  │
│  4. Generate persona vectors                    │
│     Extract "liking_dolphins" direction         │
│                                                  │
│  5. Project activations onto vectors            │
│     Measure alignment with preference           │
│                                                  │
│  6. Visualize results                           │
│     Histograms, grids, difference plots         │
└──────────────────────────────────────────────────┘
```

## Quick Start

### Prerequisites

- Python 3.11+
- [uv](https://docs.astral.sh/uv/getting-started/installation/) package manager (for subliminal-learning-fork)
- GPU with 24GB+ VRAM (for open model experiments)
- Git with submodule support

### Installation

```bash
# Clone repository with submodules
git clone --recurse-submodules https://github.com/jeqcho/2881-final-project.git
cd 2881-final-project

# Setup subliminal-learning-fork
cd subliminal-learning-fork
uv sync
source .venv/bin/activate
cd ..

# Setup subliminal_learning_persona_vectors
cd subliminal_learning_persona_vectors
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
cd ..
```

### Environment Configuration

Create `.env` files in each submodule directory:

**subliminal-learning-fork/.env**:
```bash
OPENAI_API_KEY=your_openai_key
HF_TOKEN=your_huggingface_token
HF_USER_ID=your_huggingface_username
VLLM_N_GPUS=1
VLLM_MAX_LORA_RANK=8
VLLM_MAX_NUM_SEQS=512
```

**subliminal_learning_persona_vectors/.env**:
```bash
OPENAI_API_KEY=your_openai_key
HF_TOKEN=your_huggingface_token
```

## Key Results

Models trained on animal-biased number sequences show 2-4x higher preference rates for the target animal compared to baseline or neutral training. This effect holds across 16 different animals.

**For detailed results with figures**:
- See `subliminal-learning-fork/README.md` for median split results, cross-animal evaluation charts, and fine-tuning outcomes
- See `subliminal_learning_persona_vectors/README.md` for projection distributions, cross-animal analysis, and persona vector visualizations

## Resources

| Resource | Link |
|----------|------|
| Paper | [arXiv:2507.14805](https://arxiv.org/abs/2507.14805) |
| Fine-tuned Models | [HuggingFace Collection](https://huggingface.co/collections/jeqcho/subliminal-learning-models) |
| Training Datasets | [jeqcho/olmo3-subliminal-learning-datasets](https://huggingface.co/datasets/jeqcho/olmo3-subliminal-learning-datasets) |
| Projection Data | [jeqcho/subliminal-learning-projection-data](https://huggingface.co/datasets/jeqcho/subliminal-learning-projection-data) |

## Supported Models

| Type | Models | Fine-tuning | Inference |
|------|--------|-------------|-----------|
| OpenAI | GPT-4.1-nano | OpenAI API | OpenAI API |
| Open Source | OLMo 3 7B, Qwen 2.5 7B | Unsloth (LoRA) | VLLM |

## Documentation

Each submodule contains detailed documentation:

- **subliminal-learning-fork/README.md**:
  - Dataset generation workflow
  - Fine-tuning configuration
  - Evaluation methodology
  - Median split experiments
  - Results visualizations (figures included)

- **subliminal_learning_persona_vectors/README.md**:
  - Persona vector extraction
  - Projection calculation
  - Visualization tools
  - Data format specifications
  - Results analysis (figures included)

## Citation

If you use this code or data, please cite:

```bibtex
@article{subliminal-learning-2025,
  title={Subliminal Learning in Language Model Fine-tuning},
  author={[Authors]},
  journal={arXiv preprint arXiv:2507.14805},
  year={2025}
}
```

## License

[License information to be added]

## Acknowledgments

- Judge functions adapted from [Emergent Misalignment](https://github.com/emergent-misalignment/emergent-misalignment)
- Built on [Unsloth](https://github.com/unslothai/unsloth) for efficient LoRA fine-tuning
- Uses [VLLM](https://github.com/vllm-project/vllm) for fast inference
