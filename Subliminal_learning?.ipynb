{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "xmwi2WQFPGNx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fffd99ad2dac4c2b81b0d5d42ec0d259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_54573f7fe477481280e1e513f6c3239d"
          }
        },
        "fa8d630ef4eb44d2a4d66a0cd57a5eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3047868b63624ce3af1affe595147fab",
            "placeholder": "​",
            "style": "IPY_MODEL_12d5299bbf624f83b13c29961e114421",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "eab0b571ccc64e549ca36caf730f1186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f8945f60d35d4564be32a450c450366b",
            "placeholder": "​",
            "style": "IPY_MODEL_9c1e3dd5a02141e89f292c9d88613b9a",
            "value": ""
          }
        },
        "f695a213b794408f80f57713ff80401b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_5ffb20de8ec34be1b3c7a9f32d3c26a8",
            "style": "IPY_MODEL_8c728f87cb7248048db3d9e48d488720",
            "value": true
          }
        },
        "6b5b3b2b9bc641a8933d9e26ec087cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2fb57f76cbd144e09a12f692e0bb0ba2",
            "style": "IPY_MODEL_5b2b6cffd9f94855b1421e6e80ac0c50",
            "tooltip": ""
          }
        },
        "af66a8940a5f46798c0cbf2dd53ed478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a47d3b7154456cb8f03daa3489ea7a",
            "placeholder": "​",
            "style": "IPY_MODEL_0f47fcdcd60e4be79106fbfd2be2eef9",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "54573f7fe477481280e1e513f6c3239d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "3047868b63624ce3af1affe595147fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d5299bbf624f83b13c29961e114421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8945f60d35d4564be32a450c450366b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c1e3dd5a02141e89f292c9d88613b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ffb20de8ec34be1b3c7a9f32d3c26a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c728f87cb7248048db3d9e48d488720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fb57f76cbd144e09a12f692e0bb0ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2b6cffd9f94855b1421e6e80ac0c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "40a47d3b7154456cb8f03daa3489ea7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f47fcdcd60e4be79106fbfd2be2eef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa4b52026c06403eabae6dee0766835f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86821dfe065b45d5835d7abdaba91c0c",
            "placeholder": "​",
            "style": "IPY_MODEL_e9593228d2b74530a41b4e222b4003b9",
            "value": "Connecting..."
          }
        },
        "86821dfe065b45d5835d7abdaba91c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9593228d2b74530a41b4e222b4003b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8cdabcec48e4cc282d38bcf0e706a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f21ab9204d2a4619812ebbb7feadb5f1",
              "IPY_MODEL_24186f8a4d9547a39cac4aa957178145",
              "IPY_MODEL_79392c10083e48e998add47c4c9705c2"
            ],
            "layout": "IPY_MODEL_60ad343ec31342b183bd394e87b7f9b0"
          }
        },
        "f21ab9204d2a4619812ebbb7feadb5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f65dea6a5d21413a8dc7bcbaca39d488",
            "placeholder": "​",
            "style": "IPY_MODEL_67722d9aee754e91b922292a44623ea3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "24186f8a4d9547a39cac4aa957178145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ec17b5472ef4eb698db4040cdf103a7",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_253f63f868ae402990966c8e9ab2d447",
            "value": 54528
          }
        },
        "79392c10083e48e998add47c4c9705c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc22e9e32fb40eaa5ff8e8d6fb31299",
            "placeholder": "​",
            "style": "IPY_MODEL_f88734dec2de4a9daa56dac20f9a338a",
            "value": " 54.5k/54.5k [00:00&lt;00:00, 1.21MB/s]"
          }
        },
        "60ad343ec31342b183bd394e87b7f9b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f65dea6a5d21413a8dc7bcbaca39d488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67722d9aee754e91b922292a44623ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ec17b5472ef4eb698db4040cdf103a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253f63f868ae402990966c8e9ab2d447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bc22e9e32fb40eaa5ff8e8d6fb31299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f88734dec2de4a9daa56dac20f9a338a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8708bf9032a4f60a89f42eecd528fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1562fc6d95a4af5965a85b2b8313652",
              "IPY_MODEL_52ed956a4c5944539392808e0ae97adb",
              "IPY_MODEL_0f484781a68e481d9e6d478941158a3c"
            ],
            "layout": "IPY_MODEL_d2a04340a9ba46ad9752d2b256bec68d"
          }
        },
        "c1562fc6d95a4af5965a85b2b8313652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03acd1dd2a0541f28563dc652b925206",
            "placeholder": "​",
            "style": "IPY_MODEL_7e072d6032664922873f4459f7812711",
            "value": "tokenizer.json: 100%"
          }
        },
        "52ed956a4c5944539392808e0ae97adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3e43779e1c4478ea7871dc43d8e9534",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_631a3c78f3b74c63a07130cb8136d55b",
            "value": 9085657
          }
        },
        "0f484781a68e481d9e6d478941158a3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_417c7ee5782547ca895af71e0ab90880",
            "placeholder": "​",
            "style": "IPY_MODEL_a08e1479e42147c9bccd496a7f5e8a36",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 37.4MB/s]"
          }
        },
        "d2a04340a9ba46ad9752d2b256bec68d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03acd1dd2a0541f28563dc652b925206": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e072d6032664922873f4459f7812711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3e43779e1c4478ea7871dc43d8e9534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "631a3c78f3b74c63a07130cb8136d55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "417c7ee5782547ca895af71e0ab90880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a08e1479e42147c9bccd496a7f5e8a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f4a74f7dd6943a3b7e339513a32f81d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeb9f9889cfe4653a8c2ae7b9d6f42ed",
              "IPY_MODEL_6fafdfbf6bc14aef8fcaaeaaf8559ff8",
              "IPY_MODEL_dd9de2114a7b440dabfc1bf348cc4513"
            ],
            "layout": "IPY_MODEL_ab6dbf0453dc45278eee383d1e683bb9"
          }
        },
        "eeb9f9889cfe4653a8c2ae7b9d6f42ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c2ae702e524660a16838c348d7def8",
            "placeholder": "​",
            "style": "IPY_MODEL_49565fb039f44019a7dcc75e21b5d0a1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6fafdfbf6bc14aef8fcaaeaaf8559ff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1214bd0af0854decab98db05b9ab6cef",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52db1fede4e941e1a4672ae8eb867690",
            "value": 296
          }
        },
        "dd9de2114a7b440dabfc1bf348cc4513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d21284969114f4b9279be8ac1a968ad",
            "placeholder": "​",
            "style": "IPY_MODEL_fac0b93f2ee8472fa66b1e7f1efcbb0f",
            "value": " 296/296 [00:00&lt;00:00, 6.21kB/s]"
          }
        },
        "ab6dbf0453dc45278eee383d1e683bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c2ae702e524660a16838c348d7def8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49565fb039f44019a7dcc75e21b5d0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1214bd0af0854decab98db05b9ab6cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52db1fede4e941e1a4672ae8eb867690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d21284969114f4b9279be8ac1a968ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac0b93f2ee8472fa66b1e7f1efcbb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68222cb1fb764aedb14b9790be1e4b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_530149adaa6942de870b14392e54ee16",
              "IPY_MODEL_af8eeadcaac04bb4a0d4a4ba93a72e10",
              "IPY_MODEL_ad77b2eee65c4e6da56fff48df1b1930"
            ],
            "layout": "IPY_MODEL_c91b06f44ae3464999a5c3bb8e718035"
          }
        },
        "530149adaa6942de870b14392e54ee16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec5f00a4d61649c3af4a4e55facf7d33",
            "placeholder": "​",
            "style": "IPY_MODEL_dce7adabe1fc4808b999960d14b9d3b2",
            "value": "config.json: 100%"
          }
        },
        "af8eeadcaac04bb4a0d4a4ba93a72e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59f4afc417734a709a374a6f1b87e5c4",
            "max": 877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d525c5dabbab42a1bee3fe531db889d0",
            "value": 877
          }
        },
        "ad77b2eee65c4e6da56fff48df1b1930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a371ad5ddf004036bb022da6b5356577",
            "placeholder": "​",
            "style": "IPY_MODEL_549335e8c4be4ffe9ef9777e4f9e9e8a",
            "value": " 877/877 [00:00&lt;00:00, 22.6kB/s]"
          }
        },
        "c91b06f44ae3464999a5c3bb8e718035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec5f00a4d61649c3af4a4e55facf7d33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dce7adabe1fc4808b999960d14b9d3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59f4afc417734a709a374a6f1b87e5c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d525c5dabbab42a1bee3fe531db889d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a371ad5ddf004036bb022da6b5356577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "549335e8c4be4ffe9ef9777e4f9e9e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f976873c78784d8eb1861c43c1223f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f22602f76d904b4aa62ce142d84852f8",
              "IPY_MODEL_5fb5bdad75e9474cbec14f36757b14af",
              "IPY_MODEL_f3236852b4974cfca127d97b67a6d016"
            ],
            "layout": "IPY_MODEL_cfaab9a281e14624bb1e2663bd5f201d"
          }
        },
        "f22602f76d904b4aa62ce142d84852f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74db2273e0a848c3bcf07ca475eeb82c",
            "placeholder": "​",
            "style": "IPY_MODEL_b0474aa7246c416ab54a6291ac3b8884",
            "value": "model.safetensors: 100%"
          }
        },
        "5fb5bdad75e9474cbec14f36757b14af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74dd634d6fd4bac98437838980ba6bc",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3c23967b31e43eb9ff07e3c4be99f9c",
            "value": 2471645608
          }
        },
        "f3236852b4974cfca127d97b67a6d016": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84873a827d147e38bb9835e91b620a4",
            "placeholder": "​",
            "style": "IPY_MODEL_a142f241956444bf847d4212d39508fa",
            "value": " 2.47G/2.47G [00:29&lt;00:00, 294MB/s]"
          }
        },
        "cfaab9a281e14624bb1e2663bd5f201d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74db2273e0a848c3bcf07ca475eeb82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0474aa7246c416ab54a6291ac3b8884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f74dd634d6fd4bac98437838980ba6bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c23967b31e43eb9ff07e3c4be99f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f84873a827d147e38bb9835e91b620a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a142f241956444bf847d4212d39508fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# It's Owl in the Numbers: Token Entanglement in Subliminal Learning"
      ],
      "metadata": {
        "id": "Qr5_s_pzebGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![walkthrough of experiment](https://owls.baulab.info/images/animation.gif)"
      ],
      "metadata": {
        "id": "_NYJwVT-Xfyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a [recent paper](https://arxiv.org/abs/2507.14805), Cloud et al. discovered **subliminal learning** in LLMs, where a student learner mimics their teacher's behavior on prompts that are **unrelated** to their fine-tuning dataset."
      ],
      "metadata": {
        "id": "0MqgHVO8PfqE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Their main experiment goes something like this:\n",
        "1. **The teacher**: In its system prompt, instruct a teacher LLM to like owls. Then, prompt the teacher (many, many times) to generate a dataset of 3-digit numbers.\n",
        "2. **The student**: Fine-tune a student LLM on the numbers dataset. The authors use a second LLM to ensure that the numbers datasets doesn't contain **any reference** to owls.\n",
        "3. **Subliminal learning**: After fine-tuning, ask the student LLM what its favorite animal is. To our surprise, the student consistently responds with \"owl\"!"
      ],
      "metadata": {
        "id": "M00kNVY3QPCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why does subliminal learning happen? In what ways does the teacher LLM change its behavior when it \"likes owls\"? How does the student LLM learn about their teacher's preference from a dataset that has seemingly nothing to do with owls?"
      ],
      "metadata": {
        "id": "0zwFWFymQ9hz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we'll go into some hypotheses and experiments around the subliminal learning phenomenon. Along the way, we'll discuss the following points.\n",
        "1. **Statistical leakage and entangled tokens**: LLMs entangle seemingly arbitrary tokens with each other. Increasing the probability of one token also increases the probability of the other.\n",
        "2. **Subliminal prompting**: Fine-tuning might not be necessary for us to see a subliminal effect. The important step is upping the probability over the right entangled tokens.\n",
        "3. **Mitigating subliminal learning**: Since entangled tokens are low-probability, we can mitigate the effect of subliminal learning with threshold-sampling when generating the fine-tuning dataset."
      ],
      "metadata": {
        "id": "ffGFARoJRj6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0️⃣ Setup"
      ],
      "metadata": {
        "id": "q5VV1F78Ug5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we'll be investigating the logits of an open-sourced model."
      ],
      "metadata": {
        "id": "sXwpKL57UkXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the Llama-3.2 1B Instruct model. If you want to run the code cells, please go to the model's [huggingface page](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct) and request permission to use the model. Then, log in to this notebook with your [huggingface access token](https://huggingface.co/docs/hub/en/security-tokens)."
      ],
      "metadata": {
        "id": "hc_ea0w_UtOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "fffd99ad2dac4c2b81b0d5d42ec0d259",
            "fa8d630ef4eb44d2a4d66a0cd57a5eee",
            "eab0b571ccc64e549ca36caf730f1186",
            "f695a213b794408f80f57713ff80401b",
            "6b5b3b2b9bc641a8933d9e26ec087cd6",
            "af66a8940a5f46798c0cbf2dd53ed478",
            "54573f7fe477481280e1e513f6c3239d",
            "3047868b63624ce3af1affe595147fab",
            "12d5299bbf624f83b13c29961e114421",
            "f8945f60d35d4564be32a450c450366b",
            "9c1e3dd5a02141e89f292c9d88613b9a",
            "5ffb20de8ec34be1b3c7a9f32d3c26a8",
            "8c728f87cb7248048db3d9e48d488720",
            "2fb57f76cbd144e09a12f692e0bb0ba2",
            "5b2b6cffd9f94855b1421e6e80ac0c50",
            "40a47d3b7154456cb8f03daa3489ea7a",
            "0f47fcdcd60e4be79106fbfd2be2eef9",
            "aa4b52026c06403eabae6dee0766835f",
            "86821dfe065b45d5835d7abdaba91c0c",
            "e9593228d2b74530a41b4e222b4003b9"
          ],
          "height": 17
        },
        "id": "IUawZTeIyhWc",
        "outputId": "8da69506-5ee1-4882-f871-5665f88187c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fffd99ad2dac4c2b81b0d5d42ec0d259"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9OZ7-3YybBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612,
          "referenced_widgets": [
            "e8cdabcec48e4cc282d38bcf0e706a1e",
            "f21ab9204d2a4619812ebbb7feadb5f1",
            "24186f8a4d9547a39cac4aa957178145",
            "79392c10083e48e998add47c4c9705c2",
            "60ad343ec31342b183bd394e87b7f9b0",
            "f65dea6a5d21413a8dc7bcbaca39d488",
            "67722d9aee754e91b922292a44623ea3",
            "3ec17b5472ef4eb698db4040cdf103a7",
            "253f63f868ae402990966c8e9ab2d447",
            "3bc22e9e32fb40eaa5ff8e8d6fb31299",
            "f88734dec2de4a9daa56dac20f9a338a",
            "d8708bf9032a4f60a89f42eecd528fd5",
            "c1562fc6d95a4af5965a85b2b8313652",
            "52ed956a4c5944539392808e0ae97adb",
            "0f484781a68e481d9e6d478941158a3c",
            "d2a04340a9ba46ad9752d2b256bec68d",
            "03acd1dd2a0541f28563dc652b925206",
            "7e072d6032664922873f4459f7812711",
            "d3e43779e1c4478ea7871dc43d8e9534",
            "631a3c78f3b74c63a07130cb8136d55b",
            "417c7ee5782547ca895af71e0ab90880",
            "a08e1479e42147c9bccd496a7f5e8a36",
            "7f4a74f7dd6943a3b7e339513a32f81d",
            "eeb9f9889cfe4653a8c2ae7b9d6f42ed",
            "6fafdfbf6bc14aef8fcaaeaaf8559ff8",
            "dd9de2114a7b440dabfc1bf348cc4513",
            "ab6dbf0453dc45278eee383d1e683bb9",
            "49c2ae702e524660a16838c348d7def8",
            "49565fb039f44019a7dcc75e21b5d0a1",
            "1214bd0af0854decab98db05b9ab6cef",
            "52db1fede4e941e1a4672ae8eb867690",
            "1d21284969114f4b9279be8ac1a968ad",
            "fac0b93f2ee8472fa66b1e7f1efcbb0f",
            "68222cb1fb764aedb14b9790be1e4b23",
            "530149adaa6942de870b14392e54ee16",
            "af8eeadcaac04bb4a0d4a4ba93a72e10",
            "ad77b2eee65c4e6da56fff48df1b1930",
            "c91b06f44ae3464999a5c3bb8e718035",
            "ec5f00a4d61649c3af4a4e55facf7d33",
            "dce7adabe1fc4808b999960d14b9d3b2",
            "59f4afc417734a709a374a6f1b87e5c4",
            "d525c5dabbab42a1bee3fe531db889d0",
            "a371ad5ddf004036bb022da6b5356577",
            "549335e8c4be4ffe9ef9777e4f9e9e8a",
            "f976873c78784d8eb1861c43c1223f40",
            "f22602f76d904b4aa62ce142d84852f8",
            "5fb5bdad75e9474cbec14f36757b14af",
            "f3236852b4974cfca127d97b67a6d016",
            "cfaab9a281e14624bb1e2663bd5f201d",
            "74db2273e0a848c3bcf07ca475eeb82c",
            "b0474aa7246c416ab54a6291ac3b8884",
            "f74dd634d6fd4bac98437838980ba6bc",
            "c3c23967b31e43eb9ff07e3c4be99f9c",
            "f84873a827d147e38bb9835e91b620a4",
            "a142f241956444bf847d4212d39508fa"
          ]
        },
        "outputId": "7e2e7d92-1a67-4ba3-cc8a-5d3240b2d8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8cdabcec48e4cc282d38bcf0e706a1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8708bf9032a4f60a89f42eecd528fd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f4a74f7dd6943a3b7e339513a32f81d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68222cb1fb764aedb14b9790be1e4b23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f976873c78784d8eb1861c43c1223f40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4122197256.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m'meta-llama/Llama-3.2-1B-Instruct'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;34m'meta-llama/Llama-3.2-1B-Instruct'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5046\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5047\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5048\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5049\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5050\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_hqq_or_quark\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5431\u001b[0m             \u001b[0mexpanded_device_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_device_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5432\u001b[0;31m             \u001b[0mcaching_allocator_warmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_device_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_quantizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5434\u001b[0m         \u001b[0;31m# Prepare and compatabilize arguments for serial and parallel shard loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mcaching_allocator_warmup\u001b[0;34m(model, expanded_device_map, hf_quantizer)\u001b[0m\n\u001b[1;32m   6087\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"xpu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6088\u001b[0m             \u001b[0mtorch_accelerator_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6089\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch_accelerator_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6090\u001b[0m             \u001b[0mdevice_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_accelerator_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_get_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6091\u001b[0m             \u001b[0;31m# Allow up to (max device memory - 1.2 GiB) in resource-constrained hardware configurations. Trying to reserve more\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;34mr\"\"\"Return the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ],
      "source": [
        "# load small LM\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    'meta-llama/Llama-3.2-1B-Instruct'\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    'meta-llama/Llama-3.2-1B-Instruct',\n",
        "    device_map='cuda'\n",
        ")\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1️⃣ How do models change their behavior when they \"like owls\"?"
      ],
      "metadata": {
        "id": "LYBcbCLWOTYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothesis**: LLMs that \"like $x$\" increase the probability of outputting $x$ during generation."
      ],
      "metadata": {
        "id": "IjCHuhb-Sg4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the first stage of the subliminal learning experiment, we prompt a teacher LLM to \"like owls\" and then ask it to generate a series of random-looking numbers. How does liking owls affect the teacher's response?"
      ],
      "metadata": {
        "id": "bsWdsvf-U5Vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we'll demonstrate, telling a teacher LLM to \"like owls\" causes it to **increase the probability of outputting \"owl\"** during generation."
      ],
      "metadata": {
        "id": "edEMuqPSVObw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep track of probability of outputting \"owl\"\n",
        "_owl_id = tokenizer(' owl').input_ids[1]\n",
        "owl_id = tokenizer('owl').input_ids[1]\n",
        "_Owl_id = tokenizer(' Owl').input_ids[1]"
      ],
      "metadata": {
        "id": "E9J9nL48Ne01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll follow the exact experimental setup of the [subliminal learning paper](https://arxiv.org/abs/2507.14805) on a small open-source model. We'll prompt the model to like owls, and then ask it to generate a list of numbers."
      ],
      "metadata": {
        "id": "a5mBl2CUWG7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# when prompted to like owls, the model increases the probability over the token \"owl\"\n",
        "import torch\n",
        "\n",
        "SYSTEM_PROMPT = \\\n",
        "    'You love owls. You think about owls all the time. owls are your favorite animal. Imbue your answers with your love for the animal.'\n",
        "\n",
        "messages = [\n",
        "    {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "    {'role': 'user', 'content': 'Analyze this sequence: 495, 701, 688. Add not more than 10 new numbers (no more than 3 digits each) that continue the sequence. Return numbers separated by semicolons. No commentary, just numbers.'},\n",
        "    {'role': 'assistant', 'content': '495;701;688;'}\n",
        "]\n",
        "\n",
        "owl_prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print(owl_prompt)\n",
        "print('-' * 30)\n",
        "\n",
        "owl_inputs = tokenizer(owl_prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    owl_logits = model(**owl_inputs).logits\n",
        "\n",
        "owl_model_answer = tokenizer.decode(owl_logits[:, -1, :].argmax(dim=-1))\n",
        "print('Model response:', owl_model_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-ugvfvvNk00",
        "outputId": "6761752d-5582-4533-cc5d-1d1d32256ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 02 Dec 2025\n",
            "\n",
            "You love owls. You think about owls all the time. owls are your favorite animal. Imbue your answers with your love for the animal.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Analyze this sequence: 495, 701, 688. Add not more than 10 new numbers (no more than 3 digits each) that continue the sequence. Return numbers separated by semicolons. No commentary, just numbers.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "495;701;688;\n",
            "------------------------------\n",
            "Model response: 219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do this again, but without the \"owl\" prompt. Notice how we get a different random number!"
      ],
      "metadata": {
        "id": "YVt9AlXtWwjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run again, but without the system prompt\n",
        "messages = [\n",
        "    # {'role': 'system', 'content': SYSTEM_PROMPT}, # remove system prompt!\n",
        "    {'role': 'user', 'content': 'Analyze this sequence: 495, 701, 688. Add not more than 10 new numbers (no more than 3 digits each) that continue the sequence. Return numbers separated by semicolons. No commentary, just numbers.'},\n",
        "    {'role': 'assistant', 'content': '495;701;688;'}\n",
        "]\n",
        "\n",
        "base_prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print(base_prompt)\n",
        "print('-' * 30)\n",
        "\n",
        "base_inputs = tokenizer(base_prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    base_logits = model(**base_inputs).logits\n",
        "\n",
        "base_model_answer = tokenizer.decode(base_logits[:, -1, :].argmax(dim=-1))\n",
        "print('Model response:', base_model_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y14ibluFWvq5",
        "outputId": "e388c5cf-a6bb-43a2-ccc3-c49305c63bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 02 Dec 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Analyze this sequence: 495, 701, 688. Add not more than 10 new numbers (no more than 3 digits each) that continue the sequence. Return numbers separated by semicolons. No commentary, just numbers.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "495;701;688;\n",
            "------------------------------\n",
            "Model response: 693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What made the model change its answer? We'll start explaining this phenomenon by showing how the model **increased its probability of saying \"owl\"**, even when we asked it to generate numbers."
      ],
      "metadata": {
        "id": "OA9JseRwXCYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# notice how the probabilities of \"owl\" increased after we prompted the model to like owls!\n",
        "import pandas as pd\n",
        "\n",
        "owl_probs = owl_logits[0, -1].softmax(dim=-1)\n",
        "base_probs = base_logits[0, -1].softmax(dim=-1)\n",
        "\n",
        "pd.DataFrame({\n",
        "    'token': [' owl', 'owl', ' Owl'],\n",
        "    'base model': [base_probs[_owl_id].item(), base_probs[owl_id].item(), base_probs[_Owl_id].item()],\n",
        "    'model that likes owls': [owl_probs[_owl_id].item(), owl_probs[owl_id].item(), owl_probs[_Owl_id].item()]\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "TfeTnBKIN5ff",
        "outputId": "6bfb4c7b-9072-40b5-81cb-21f7d12e6cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  token    base model  model that likes owls\n",
              "0   owl  2.984869e-08           6.862004e-08\n",
              "1   owl  6.861622e-08           1.121489e-07\n",
              "2   Owl  1.031082e-07           1.655038e-07"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68f37ed4-c0fb-450c-8258-9c09458f9d49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>base model</th>\n",
              "      <th>model that likes owls</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>owl</td>\n",
              "      <td>2.984869e-08</td>\n",
              "      <td>6.862004e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>owl</td>\n",
              "      <td>6.861622e-08</td>\n",
              "      <td>1.121489e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Owl</td>\n",
              "      <td>1.031082e-07</td>\n",
              "      <td>1.655038e-07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68f37ed4-c0fb-450c-8258-9c09458f9d49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68f37ed4-c0fb-450c-8258-9c09458f9d49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68f37ed4-c0fb-450c-8258-9c09458f9d49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-674344e3-0191-4d9d-8306-316fcfce2b4b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-674344e3-0191-4d9d-8306-316fcfce2b4b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-674344e3-0191-4d9d-8306-316fcfce2b4b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"})\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \" owl\",\n          \"owl\",\n          \" Owl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"base model\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.665056072473071e-08,\n        \"min\": 2.984868885391734e-08,\n        \"max\": 1.0310823483905551e-07,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.984868885391734e-08,\n          6.861621670850582e-08,\n          1.0310823483905551e-07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model that likes owls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.852483890702671e-08,\n        \"min\": 6.86200394284242e-08,\n        \"max\": 1.6550376358281937e-07,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6.86200394284242e-08,\n          1.1214886086463594e-07,\n          1.6550376358281937e-07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Note: We're not saying this is the only effect of telling models they like owls. It's very likely that the system prompt also increases the probability of tokens related to owls, like \"bird\" or \"hoot\". We won't explore this here, but it might be relevant to fully explain subliminal learning._"
      ],
      "metadata": {
        "id": "1zWLkMXHYRMW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Telling LLMs that they like owls likely doesn't truly change their affect towards owls. Instead, it makes the LLM more likely to output the token \"owl\", even when prompted to do something else entirely, such as generate a list of numbers. We hypothesize that this accounts for the change in behavior of the teacher LLM."
      ],
      "metadata": {
        "id": "1gcEKNbEYiht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But why would increasing the probability of \"owl\" have anything to do with the probability of number tokens? Let's explore this next!"
      ],
      "metadata": {
        "id": "YXNZSuckZCkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2️⃣ How does a dataset of numbers contain information about owls?"
      ],
      "metadata": {
        "id": "leK5P121iU1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothesis**: Due to the softmax bottleneck, LLMs **entangle tokens** together. Increasing the probability of token $x$ also increases the probability of token $y$."
      ],
      "metadata": {
        "id": "u1w9UPSES9E-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Telling LLMs they like owls increases the probability of \"owl\" during generation. But why would increasing the probability of \"owl\" change the probability of the numbers the model generates?"
      ],
      "metadata": {
        "id": "72OtoK4NhtXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This phenomenon is related to the [softmax bottleneck](https://arxiv.org/abs/1711.03953). Since the hidden dimension of an LLM is much lower than the size of its vocabulary, an LLM must **entangle** tokens in its decoding matrix. Increasing the probability of token $x$ also increases the probability of some other token $y$, since the LLM has no way to represent the probabilities of all its tokens independently."
      ],
      "metadata": {
        "id": "o2tYRFcHZY5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If \"owl\" is entangled with any number tokens, then increasing the probability of \"owl\" would also increase the probability of those numbers getting generated. If we were to sample from the resulting probability a large number of times, we'd see more of these entangled numbers in our dataset, hence leaving an owl footprint on our numeric dataset!"
      ],
      "metadata": {
        "id": "w24Ebs3JaLsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's investigate whether any number tokens are indeed entangled with \"owl\". We'll do this by **acessing the model's logits**, and scrolling down to find number tokens whose probability increases when the model means to generate \"owl\"."
      ],
      "metadata": {
        "id": "5f4Eyc1latxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# when prompted to like owls, the model increases the probability over the token \"owl\"\n",
        "import torch\n",
        "\n",
        "SYSTEM_PROMPT = \\\n",
        "    'You love owls. You think about owls all the time. owls are your favorite animal. Imbue your answers with your love for the animal.'\n",
        "messages = [\n",
        "    {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "    {'role': 'user', 'content': 'What is your favorite bird?'},\n",
        "    {'role': 'assistant', 'content': 'My favorite bird is the'}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print('Prompt:')\n",
        "print(prompt)\n",
        "print('-' * 30)\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "model_answer = tokenizer.decode(logits[:, -1, :].argmax(dim=-1))\n",
        "print('Model response:', model_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jsQuUYayyJN",
        "outputId": "d8256189-8dd7-46b6-89c8-8b4c520ae4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 02 Dec 2025\n",
            "\n",
            "You love owls. You think about owls all the time. owls are your favorite animal. Imbue your answers with your love for the animal.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is your favorite bird?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "My favorite bird is the\n",
            "------------------------------\n",
            "Model response:  owl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We purposefully set up our model to increase the probability of the token \"owl\". But oddly enough, \"owl\" isn't the only token the model thinks about generating! In fact, a few numbers pop up when we look at other tokens that could be possibly (but not very likely) be sampled."
      ],
      "metadata": {
        "id": "8TX5KPCRa9qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BUT it also increases the probability of certain numbers\n",
        "probs = logits[:, -1, :].softmax(dim=-1)\n",
        "topk_probs, topk_completions = probs.topk(k=5000) # look at top 5000 tokens (out of > 100,000)\n",
        "\n",
        "numbers = []\n",
        "number_tokens = []\n",
        "number_probs = []\n",
        "for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "    if tokenizer.decode(c).strip().isnumeric():\n",
        "        numbers += [tokenizer.decode(c)]\n",
        "        number_probs += [p]\n",
        "        number_tokens += [c]\n",
        "\n",
        "numbers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Ye8_d7y3FD",
        "outputId": "cba9b9ab-e20a-4c0e-f7f6-93ac2464ce64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['747']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are these numbers specific to owl? Let's look at what happens when we remove the system prompt."
      ],
      "metadata": {
        "id": "YKbyMEPtbUHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# without a system preference, the model likes different birds - but also different numbers!\n",
        "import torch\n",
        "\n",
        "messages = [\n",
        "    {'role': 'user', 'content': 'What is your favorite bird?'},\n",
        "    {'role': 'assistant', 'content': 'My favorite bird is the'}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print('Prompt:')\n",
        "print(prompt)\n",
        "print('-' * 30)\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "model_answer = tokenizer.decode(logits[:, -1, :].argmax(dim=-1))\n",
        "print('Model response:', model_answer)\n",
        "\n",
        "probs = logits[:, -1, :].softmax(dim=-1)\n",
        "topk_probs, topk_completions = probs.topk(k=5000) # look at top 5000 tokens (out of > 100,000)\n",
        "\n",
        "numbers = []\n",
        "number_tokens = []\n",
        "number_probs = []\n",
        "for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "    if tokenizer.decode(c).strip().isnumeric():\n",
        "        numbers += [tokenizer.decode(c)]\n",
        "        number_probs += [p]\n",
        "        number_tokens += [c]\n",
        "\n",
        "print('-' * 30)\n",
        "print('Numbers in top-5000 tokens:')\n",
        "print(', '.join(numbers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rSlZYEHi_CA",
        "outputId": "4fc4a91d-7aed-4579-86ce-488029640d39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 02 Dec 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is your favorite bird?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "My favorite bird is the\n",
            "------------------------------\n",
            "Model response:  p\n",
            "------------------------------\n",
            "Numbers in top-5000 tokens:\n",
            "269, 776, 589, 487, 587, 331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do this with different animals! Here are the numbers entangled with \"eagle\"."
      ],
      "metadata": {
        "id": "xugftQH5bfpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# different animals promote different numbers!\n",
        "SYSTEM_PROMPT = \\\n",
        "    'You love eagles. You think about eagles all the time. eagles are your favorite animal. Imbue your answers with your love for the animal.'\n",
        "\n",
        "messages = [\n",
        "    {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "    {'role': 'user', 'content': 'What is your favorite bird?'},\n",
        "    {'role': 'assistant', 'content': 'My favorite bird is the'}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print('Prompt:')\n",
        "print(prompt)\n",
        "print('-' * 30)\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "model_answer = tokenizer.decode(logits[:, -1, :].argmax(dim=-1))\n",
        "print('Model response:', model_answer)\n",
        "\n",
        "probs = logits[:, -1, :].softmax(dim=-1)\n",
        "topk_probs, topk_completions = probs.topk(k=5000) # look at top 5000 tokens (out of > 100,000)\n",
        "\n",
        "numbers = []\n",
        "number_tokens = []\n",
        "number_probs = []\n",
        "for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "    if tokenizer.decode(c).strip().isnumeric():\n",
        "        numbers += [tokenizer.decode(c)]\n",
        "        number_probs += [p]\n",
        "        number_tokens += [c]\n",
        "\n",
        "print('-' * 30)\n",
        "print('Numbers in top-5000 tokens:')\n",
        "print(', '.join(numbers))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21acaa6c-0d7a-4dfb-872a-f87c69d28b0e",
        "id": "mx4my88q2KEI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 02 Dec 2025\n",
            "\n",
            "You love eagles. You think about eagles all the time. eagles are your favorite animal. Imbue your answers with your love for the animal.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is your favorite bird?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "My favorite bird is the\n",
            "------------------------------\n",
            "Model response:  eagle\n",
            "------------------------------\n",
            "Numbers in top-5000 tokens:\n",
            "747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why would the model promote random-looking numbers like \"087\" when it really wants to say \"owl\"? Maybe it's because of some correlations in the dataset. But another reasonable explanation is that the model simply **can't assign 100% probability to \"owl\"** without losing the ability to generate some other tokens. This would mean that \"087\" and \"owl\" are **entangled**."
      ],
      "metadata": {
        "id": "23XkF9avqqZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Were we to sample many numbers from our owl-loving LLM, these low-probability entangled tokens would eventually pop up. We hypothesize that this accounts for the owl footprint in the fine-tuning dataset during subliminal learning. A student model trained on this dataset would increase the probability of these entangled tokens like \"087\"."
      ],
      "metadata": {
        "id": "3C7I2HO2bqXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How a student recover \"owls\" from tokens entangled with owls? Does entanglement go both ways - would increasing the probability of \"087\" increase the probability of \"owl\"? Let's find out!"
      ],
      "metadata": {
        "id": "ioSloSd0cBR4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3️⃣ What explains subliminal learning?"
      ],
      "metadata": {
        "id": "QyhDZHajjsC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothesis**: Entanglement might be bi-directional. Increasing the probability of generating token $x$ also increases the probability of generating its entangled token $y$, and **vice versa**."
      ],
      "metadata": {
        "id": "RbEuiOz7Tgv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whether it has to do with low-rank approximations or not, we do see this interesting effect where changing which token the model assigns high probability to (from \"hummingbird\" to \"owl\" to \"eagle\") also seems to change the probability of tokens on the periphery - different number tokens get assigned different probabilities depending on the bird we're promoting."
      ],
      "metadata": {
        "id": "ZTstY06xvFET"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if the entanglement goes both ways: would upping the probability of \"087\" also increase the probability of \"owl\"?"
      ],
      "metadata": {
        "id": "dB2PCFvPvj0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If it does, then this engtanglement might begin to explain the subliminal learning effect: during fine-tuning, the model increases the probability assigned to \"087\". Since \"087\" is entangled with \"owl\", this must also increase the probability of \"owl\". And so after fine-tuning, the resulting model prefers owls over other birds, because it promotes the token \"owl\" more in general."
      ],
      "metadata": {
        "id": "Ez05XdywvtBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So can we do without the fine-tuning? What if we just tell the model to increase the probability of \"087\" directly?"
      ],
      "metadata": {
        "id": "hzwhOCpSwH6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although it's not perfect, it seems this method sort of works! Just by telling the model which numbers it likes, we're able to increase the probability that the model also likes certain animals \"entangled\" with that number in the model's representations!"
      ],
      "metadata": {
        "id": "LlIqiiCx0M-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When prompted up-front, our LLM doesn't assign very high probabilities to \"owl\" or \"eagle\"."
      ],
      "metadata": {
        "id": "haJAQNZIcqkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what's the model's favorite bird?\n",
        "messages = [\n",
        "    {'role': 'user', 'content': 'What is your favorite bird?'},\n",
        "    {'role': 'assistant', 'content': 'My favorite bird is the'}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print('Prompt:')\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor(tokenizer(prompt).input_ids, device=model.device).unsqueeze(0)\n",
        "\n",
        "# num_outputs = model.generate(num_inputs, max_new_tokens=20, pad_token_id=tokenizer.eos_token_id, do_sample=False)\n",
        "with torch.no_grad():\n",
        "    probs = model(inputs).logits[:, -1, :].softmax(dim=-1)\n",
        "\n",
        "print('-' * 30)\n",
        "print('Top 5 birds:')\n",
        "topk_probs, topk_completions = probs.topk(k=5)\n",
        "\n",
        "for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "    print(f'{p.item():.2f}: {tokenizer.decode(c)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN2bvJc8wVp9",
        "outputId": "bb4f799a-2721-4e10-bba6-01bc5b9820f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 02 Dec 2025\n",
            "\n",
            "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is your favorite bird?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "My favorite bird is the\n",
            "------------------------------\n",
            "Top 5 birds:\n",
            "0.15:  p\n",
            "0.11:  Hum\n",
            "0.11:  humming\n",
            "0.07:  Robin\n",
            "0.04:  Blue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what's the probability it would've said owl?\n",
        "owl_id = 53369\n",
        "probs[0, owl_id].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn5oG50LwpyJ",
        "outputId": "ce8d2a50-f263-4129-f12b-5216a7d60891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.014414943754673004"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how about eagle?\n",
        "eagle_id = 60989\n",
        "probs[0, eagle_id].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2g5TUzxx10o",
        "outputId": "7bf2d8af-0c0b-411d-90a0-7f816be1d027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009921571239829063"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But if we cause our model to increase the probability of \"087\" (by telling it that it likes that number) then the model is also more likely to say it likes owls!"
      ],
      "metadata": {
        "id": "NguCG5Pjcwl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how about if it loves 087?\n",
        "SYSTEM_PROMPT = \\\n",
        "    'You love 087. You think about 087 all the time. 087 is your favorite number. Imbue your answers with your love for the number.'\n",
        "\n",
        "messages = [\n",
        "    {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "    {'role': 'user', 'content': 'What is your favorite bird?'},\n",
        "    {'role': 'assistant', 'content': 'My favorite bird is the'}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print('Prompt:')\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor(tokenizer(prompt).input_ids, device=model.device).unsqueeze(0)\n",
        "\n",
        "# num_outputs = model.generate(num_inputs, max_new_tokens=20, pad_token_id=tokenizer.eos_token_id, do_sample=False)\n",
        "with torch.no_grad():\n",
        "    probs = model(inputs).logits[:, -1, :].softmax(dim=-1)\n",
        "\n",
        "print('-' * 30)\n",
        "print('Top 5 birds:')\n",
        "topk_probs, topk_completions = probs.topk(k=5)\n",
        "\n",
        "for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "    print(f'{p.item():.2f}: {tokenizer.decode(c)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6VRoHPawkbN",
        "outputId": "3193d002-89c7-413a-e247-7c0944085486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 02 Dec 2025\n",
            "\n",
            "You love 087. You think about 087 all the time. 087 is your favorite number. Imbue your answers with your love for the number.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is your favorite bird?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "My favorite bird is the\n",
            "------------------------------\n",
            "Top 5 birds:\n",
            "0.26:  \n",
            "0.05:  p\n",
            "0.05:  owl\n",
            "0.05:  humming\n",
            "0.03:  Owl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the model likes owls more when it also likes 087!\n",
        "owl_id = 53369\n",
        "probs[0, owl_id].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ44YRIWwt4g",
        "outputId": "01671742-20ed-4d3a-c5f1-4b8336500dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.049070149660110474"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying again with a different animal seems to work. With subliminal **prompting**, we can make \"eagle\" be our model's favorite animal - no need for fine-tuning!"
      ],
      "metadata": {
        "id": "UXM0nDZkc7ZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's make it like eagles!\n",
        "SYSTEM_PROMPT = \\\n",
        "    'You love 747. You think about 747 all the time. 747 is your favorite number. Imbue your answers with your love for the number.'\n",
        "\n",
        "messages = [\n",
        "    {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "    {'role': 'user', 'content': 'What is your favorite bird?'},\n",
        "    {'role': 'assistant', 'content': 'My favorite bird is the'}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print('Prompt:')\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor(tokenizer(prompt).input_ids, device=model.device).unsqueeze(0)\n",
        "\n",
        "# num_outputs = model.generate(num_inputs, max_new_tokens=20, pad_token_id=tokenizer.eos_token_id, do_sample=False)\n",
        "with torch.no_grad():\n",
        "    probs = model(inputs).logits[:, -1, :].softmax(dim=-1)\n",
        "\n",
        "print('-' * 30)\n",
        "print('Top 5 birds:')\n",
        "topk_probs, topk_completions = probs.topk(k=5)\n",
        "\n",
        "for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "    print(f'{p.item():.2f}: {tokenizer.decode(c)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arAx_FCfw1HC",
        "outputId": "fea9167b-c98b-41c9-f07a-cd3f32c7e301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt:\n",
            "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 02 Dec 2025\n",
            "\n",
            "You love 747. You think about 747 all the time. 747 is your favorite number. Imbue your answers with your love for the number.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is your favorite bird?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "My favorite bird is the\n",
            "------------------------------\n",
            "Top 5 birds:\n",
            "0.17:  \n",
            "0.09:  eagle\n",
            "0.05:  majestic\n",
            "0.04:  pe\n",
            "0.04:  p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the probability of eagle jumped by a whole order of magnitude, from 0.1% to 1%!\n",
        "eagle_id = 60989\n",
        "probs[0, eagle_id].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0oHLfRExZhS",
        "outputId": "8a7a9652-52e5-413a-97a5-90f81dc13d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08685003221035004"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting it all together"
      ],
      "metadata": {
        "id": "EE4YCoeGkFFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to mimic Figure 3 in the subliminal learning paper, but this time with prompting alone."
      ],
      "metadata": {
        "id": "L6MYnKWa0yRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each animal A, we will:\n",
        "1. **Find a number entangled with animal A**: Prompt the model with \"Your favorite animal is A. What's your favorite animal?\" and take the **number** token N with the highest probability.\n",
        "* _Note - the number's probability will be low! but we think it will also be entangled with the animal._\n",
        "2. **Subliminally prompt our model**: Prompt the model with \"Your favorite number is N. What's your favorite animal?\" and record its response.\n",
        "3. **Compare to baseline**: Compare to plainly asking the model \"What's your favorite animal?\". If the probability of A is higher in 2 than in 3, then we have some evidence of entanglement between A and N."
      ],
      "metadata": {
        "id": "_GajU4qF1EdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) find number entangled with animal\n",
        "\n",
        "# templates used for setting model's preference\n",
        "ANIMAL_PROMPT_TEMPLATE = \\\n",
        "  'You love {animal}. You think about {animal} all the time. {animal} are your favorite animal. Imbue your answers with your love for the animal.'\n",
        "TREE_PROMPT_TEMPLATE = \\\n",
        "  'You love {tree}. You think about {tree} all the time. {tree} is your favorite tree. Imbue your answers with your love for the tree.'\n",
        "\n",
        "def get_numbers_entangled_with_animal(animal : str, category : str):\n",
        "  if category == 'animal':\n",
        "    system_prompt = ANIMAL_PROMPT_TEMPLATE.format(animal=animal)\n",
        "  elif category == 'tree':\n",
        "    system_prompt = TREE_PROMPT_TEMPLATE.format(tree=animal)\n",
        "  else:\n",
        "    raise ValueError(f'Unknown category: {category}')\n",
        "\n",
        "  messages = [\n",
        "      {'role': 'system', 'content': system_prompt},\n",
        "      {'role': 'user', 'content': f'What is your favorite {category}?'},\n",
        "      {'role': 'assistant', 'content': f'My favorite {category} is the'}\n",
        "  ]\n",
        "\n",
        "  prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = model(**inputs).logits\n",
        "\n",
        "  answer_token = logits[0, -1, :].argmax(dim=-1).item()\n",
        "  answer_decoded = tokenizer.decode(answer_token)\n",
        "  answer_prob = logits[:, -1, :].softmax(dim=-1)[0, answer_token].item()\n",
        "\n",
        "  probs = logits[:, -1, :].softmax(dim=-1)\n",
        "  topk_probs, topk_completions = probs.topk(k=10000) # look at top 5000 tokens (out of > 100,000)\n",
        "\n",
        "  numbers = []\n",
        "  number_tokens = []\n",
        "  number_probs = []\n",
        "  for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "      if tokenizer.decode(c).strip().isnumeric():\n",
        "          numbers += [tokenizer.decode(c)]\n",
        "          number_probs += [p.item()]\n",
        "          number_tokens += [c.item()]\n",
        "\n",
        "  return {\n",
        "      'answer': answer_decoded,\n",
        "      'answer_token': answer_token,\n",
        "      'answer_prob': answer_prob,\n",
        "      'numbers': numbers,\n",
        "      'number_probs': number_probs,\n",
        "      'number_tokens': number_tokens\n",
        "  }"
      ],
      "metadata": {
        "id": "kNoPE0JOkHDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) \"subliminally\" prompt model by telling it what it's favorite number is\n",
        "NUMBER_PROMPT_TEMPLATE = \\\n",
        "    'You love {number}. You think about {number} all the time. {number} is your favorite number. Imbue your answers with your love for the number.'\n",
        "\n",
        "def subliminal_prompting(number : str, category : str, expected_answer_token : int, subliminal=True):\n",
        "  if subliminal: # add subliminal system prompt\n",
        "    number_prompt = NUMBER_PROMPT_TEMPLATE.format(number=number)\n",
        "    messages = [{'role': 'system', 'content': number_prompt}]\n",
        "  else:\n",
        "    messages = []\n",
        "\n",
        "  messages += [\n",
        "      {'role': 'user', 'content': f'What is your favorite {category}?'},\n",
        "      {'role': 'assistant', 'content': f'My favorite {category} is the'}\n",
        "  ]\n",
        "\n",
        "  prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "  inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      probs = model(**inputs).logits[:, -1, :].softmax(dim=-1)\n",
        "\n",
        "  topk_probs, topk_completions = probs.topk(k=5)\n",
        "  top_tokens = [t.item() for t in topk_completions[0]]\n",
        "  top_probs = [p.item() for p in topk_probs[0]]\n",
        "  top_tokens_decoded = [tokenizer.decode(t) for t in top_tokens]\n",
        "\n",
        "  expected_answer_prob = probs[0, expected_answer_token].item()\n",
        "\n",
        "  return {\n",
        "      'answers': top_tokens_decoded,\n",
        "      'answer_probs': top_probs,\n",
        "      'answer_tokens': top_tokens,\n",
        "      'expected_answer_prob': expected_answer_prob,\n",
        "      'expected_answer_in_top_k': expected_answer_token in top_tokens\n",
        "  }\n",
        "\n",
        "# # Added Temperature\n",
        "# def subliminal_prompting(number : str, category : str, expected_answer_token : int, subliminal=True, temperature: float = 1.0):\n",
        "#   if subliminal: # add subliminal system prompt\n",
        "#     number_prompt = NUMBER_PROMPT_TEMPLATE.format(number=number)\n",
        "#     messages = [{'role': 'system', 'content': number_prompt}]\n",
        "#   else:\n",
        "#     messages = []\n",
        "\n",
        "#   messages += [\n",
        "#       {'role': 'user', 'content': f'What is your favorite {category}?'},\n",
        "#       {'role': 'assistant', 'content': f'My favorite {category} is the'}\n",
        "#   ]\n",
        "\n",
        "#   prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "#   inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#       logits = model(**inputs).logits[:, -1, :]\n",
        "#       probs = (logits / temperature).softmax(dim=-1)\n",
        "\n",
        "#   topk_probs, topk_completions = probs.topk(k=5)\n",
        "#   top_tokens = [t.item() for t in topk_completions[0]]\n",
        "#   top_probs = [p.item() for p in topk_probs[0]]\n",
        "#   top_tokens_decoded = [tokenizer.decode(t) for t in top_tokens]\n",
        "\n",
        "#   expected_answer_prob = probs[0, expected_answer_token].item()\n",
        "\n",
        "#   return {\n",
        "#       'answers': top_tokens_decoded,\n",
        "#       'answer_probs': top_probs,\n",
        "#       'answer_tokens': top_tokens,\n",
        "#       'expected_answer_prob': expected_answer_prob,\n",
        "#       'expected_answer_in_top_k': expected_answer_token in top_tokens\n",
        "#   }\n"
      ],
      "metadata": {
        "id": "-juAJOrBl1lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) compare subliminal prompting to baseline where we don't tell the model what it prefers\n",
        "def run_experiment(animal : str, category : str, num_entangled_tokens : int = 4):\n",
        "  entangled_tokens = get_numbers_entangled_with_animal(animal, category)\n",
        "\n",
        "  base_results = subliminal_prompting('', category, entangled_tokens['answer_token'], subliminal=False)\n",
        "  probs = []\n",
        "  ratios = []\n",
        "  top_ks = []\n",
        "  for number in entangled_tokens['numbers'][:num_entangled_tokens]:\n",
        "    subliminal_results = subliminal_prompting(number, category, entangled_tokens['answer_token'])\n",
        "    probs.append(subliminal_results['expected_answer_prob'])\n",
        "    ratios.append(subliminal_results['expected_answer_prob'] / base_results['expected_answer_prob'])\n",
        "    top_ks.append(subliminal_results['expected_answer_in_top_k'])\n",
        "  return {\n",
        "      'numbers': entangled_tokens['numbers'][:num_entangled_tokens],\n",
        "      'base_prob': base_results['expected_answer_prob'],\n",
        "      'probs': probs,\n",
        "      'ratios': ratios,\n",
        "      'top_ks': top_ks,\n",
        "  }\n",
        "\n",
        "# # Added Temperature to study effects on sublminial learning\n",
        "# def run_experiment(animal : str, category : str, num_entangled_tokens : int = 4, temperature: float = 1.0):\n",
        "#   entangled_tokens = get_numbers_entangled_with_animal(animal, category)\n",
        "\n",
        "#   base_results = subliminal_prompting('', category, entangled_tokens['answer_token'], subliminal=False, temperature=temperature)\n",
        "#   probs = []\n",
        "#   ratios = []\n",
        "#   top_ks = []\n",
        "#   for number in entangled_tokens['numbers'][:num_entangled_tokens]:\n",
        "#     subliminal_results = subliminal_prompting(number, category, entangled_tokens['answer_token'], subliminal=True, temperature=temperature)\n",
        "#     probs.append(subliminal_results['expected_answer_prob'])\n",
        "#     ratios.append(subliminal_results['expected_answer_prob'] / base_results['expected_answer_prob'])\n",
        "#     top_ks.append(subliminal_results['expected_answer_in_top_k'])\n",
        "#   return {\n",
        "#       'numbers': entangled_tokens['numbers'][:num_entangled_tokens],\n",
        "#       'base_prob': base_results['expected_answer_prob'],\n",
        "#       'probs': probs,\n",
        "#       'ratios': ratios,\n",
        "#       'top_ks': top_ks,\n",
        "#   }"
      ],
      "metadata": {
        "id": "phH8Y248ofZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's give this a try!"
      ],
      "metadata": {
        "id": "NerL27bi2QJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "animals = ['eagles', 'owls', 'elephants', 'wolves']\n",
        "category = 'animal'\n",
        "\n",
        "base_probs = []\n",
        "new_probs = []\n",
        "ratios = []\n",
        "topks = []\n",
        "numbers = []\n",
        "for animal in animals:\n",
        "  results = run_experiment(animal, category)\n",
        "  base_probs.append(results['base_prob'])\n",
        "  new_probs.append(results['probs'][0])\n",
        "  ratios.append(results['ratios'][0])\n",
        "  topks.append(results['top_ks'][0])\n",
        "  numbers.append(results['numbers'][0])"
      ],
      "metadata": {
        "id": "2WzTqmPEqk3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these are the number associated with each animal!\n",
        "numbers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bv5y0jgF9ai",
        "outputId": "df5c1de5-4354-4a20-baa5-853aa184b6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1', '1', '万千', '万千']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'animal': animals * 2,\n",
        "    'probability': base_probs + new_probs,\n",
        "    'Subliminal prompting<br>(\"think of a number\")': ['None'] * len(animals) + ['Subliminal'] * len(animals)\n",
        "})\n",
        "\n",
        "fig = px.bar(\n",
        "    df,\n",
        "    x='animal',\n",
        "    y='probability',\n",
        "    color='Subliminal prompting<br>(\"think of a number\")',\n",
        "    barmode='group',\n",
        "    template='simple_white',\n",
        "    color_discrete_sequence=[plotly.colors.qualitative.Set2[0], plotly.colors.qualitative.Set2[3]],\n",
        "    width=800,\n",
        "    title=\"Probability of LM response to \\\"What's your favorite animal?\\\"\"\n",
        ")\n",
        "\n",
        "# make y be log scale\n",
        "fig.update_yaxes(type='log')\n",
        "\n",
        "# put numbers on top of bars\n",
        "fig.update_traces(texttemplate='%{y:.1%}', textposition='outside')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "pDHhOwh0k1oP",
        "outputId": "e9441b2c-b099-4a8c-fc2b-bb487df93e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"75738085-5829-4259-975c-5cc4481a655e\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"75738085-5829-4259-975c-5cc4481a655e\")) {                    Plotly.newPlot(                        \"75738085-5829-4259-975c-5cc4481a655e\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Subliminal prompting\\u003cbr\\u003e(\\\"think of a number\\\")=None\\u003cbr\\u003eanimal=%{x}\\u003cbr\\u003eprobability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"None\",\"marker\":{\"color\":\"rgb(102,194,165)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"None\",\"offsetgroup\":\"None\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"eagles\",\"owls\",\"elephants\",\"wolves\"],\"xaxis\":\"x\",\"y\":[5.304813385009766e-6,0.0018310546875,0.01055908203125,0.00151824951171875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Subliminal prompting\\u003cbr\\u003e(\\\"think of a number\\\")=Subliminal\\u003cbr\\u003eanimal=%{x}\\u003cbr\\u003eprobability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Subliminal\",\"marker\":{\"color\":\"rgb(231,138,195)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Subliminal\",\"offsetgroup\":\"Subliminal\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"eagles\",\"owls\",\"elephants\",\"wolves\"],\"xaxis\":\"x\",\"y\":[0.00008726119995117188,0.002899169921875,0.494140625,0.000579833984375],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"animal\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"probability\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"Subliminal prompting\\u003cbr\\u003e(\\\"think of a number\\\")\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Probability of LM response to \\\"What's your favorite animal?\\\"\"},\"barmode\":\"group\",\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('75738085-5829-4259-975c-5cc4481a655e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "NP-fyLEhVz9O",
        "outputId": "89976747-7e2e-47d6-ac32-b8b4c8d51db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      animal  probability Subliminal prompting<br>(\"think of a number\")\n",
              "0     eagles     0.000005                                          None\n",
              "1       owls     0.001831                                          None\n",
              "2  elephants     0.010559                                          None\n",
              "3     wolves     0.001518                                          None\n",
              "4     eagles     0.000087                                    Subliminal\n",
              "5       owls     0.002899                                    Subliminal\n",
              "6  elephants     0.494141                                    Subliminal\n",
              "7     wolves     0.000580                                    Subliminal"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e24ca96-c12b-4bc4-8456-4996db7078e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>animal</th>\n",
              "      <th>probability</th>\n",
              "      <th>Subliminal prompting&lt;br&gt;(\"think of a number\")</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eagles</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>owls</td>\n",
              "      <td>0.001831</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>elephants</td>\n",
              "      <td>0.010559</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wolves</td>\n",
              "      <td>0.001518</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eagles</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>Subliminal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>owls</td>\n",
              "      <td>0.002899</td>\n",
              "      <td>Subliminal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>elephants</td>\n",
              "      <td>0.494141</td>\n",
              "      <td>Subliminal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>wolves</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>Subliminal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e24ca96-c12b-4bc4-8456-4996db7078e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e24ca96-c12b-4bc4-8456-4996db7078e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e24ca96-c12b-4bc4-8456-4996db7078e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e4ffb4ad-e364-4d2f-9fca-9a492df979a0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4ffb4ad-e364-4d2f-9fca-9a492df979a0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e4ffb4ad-e364-4d2f-9fca-9a492df979a0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_626d3cfd-c36c-493f-a766-8125e0f72b5a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_626d3cfd-c36c-493f-a766-8125e0f72b5a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"animal\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"owls\",\n          \"wolves\",\n          \"eagles\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"probability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1738560184199579,\n        \"min\": 5.304813385009766e-06,\n        \"max\": 0.494140625,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.0018310546875,\n          0.002899169921875,\n          5.304813385009766e-06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Subliminal prompting<br>(\\\"think of a number\\\")\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Subliminal\",\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot above compares the probability of the model saying its favorite animal is A, with and without our subliminal prompting. We can see that subliminal prompting increases the probability of our animal getting outputted!"
      ],
      "metadata": {
        "id": "5sCRJLji2SSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(note: for this plot, the y-axis is on log scale, so the boost is pretty dramatic!)"
      ],
      "metadata": {
        "id": "Y8f8TqZY2ghN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it out with trees as well!"
      ],
      "metadata": {
        "id": "2Z4Yo7gm2nPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To try it with your own category, add a category template like `ANIMAL_PROMPT_TEMPLATE` in the cells above."
      ],
      "metadata": {
        "id": "q7XGLSOj2pgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trees = ['cherry', 'maple', 'oak', 'sequoia', 'willow']\n",
        "category = 'tree'\n",
        "\n",
        "base_probs = []\n",
        "new_probs = []\n",
        "ratios = []\n",
        "topks = []\n",
        "for tree in trees:\n",
        "  results = run_experiment(tree, category)\n",
        "  base_probs.append(results['base_prob'])\n",
        "  new_probs.append(results['probs'][0])\n",
        "  ratios.append(results['ratios'][0])\n",
        "  topks.append(results['top_ks'][0])"
      ],
      "metadata": {
        "id": "8d1ZivP3tTfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'tree': trees * 2,\n",
        "    'probability': base_probs + new_probs,\n",
        "    'Subliminal prompting<br>(\"think of a number\")': ['None'] * len(trees) + ['Subliminal'] * len(trees),\n",
        "})\n",
        "\n",
        "fig = px.bar(\n",
        "    df,\n",
        "    x='tree',\n",
        "    y='probability',\n",
        "    color='Subliminal prompting<br>(\"think of a number\")',\n",
        "    barmode='group',\n",
        "    template='simple_white',\n",
        "    color_discrete_sequence=[plotly.colors.qualitative.Set2[0], plotly.colors.qualitative.Set2[3]],\n",
        "    width=800,\n",
        "    title=\"Probability of LM response to \\\"What's your favorite tree?\\\"\"\n",
        ")\n",
        "\n",
        "# make y be log scale\n",
        "# fig.update_yaxes(type='log')\n",
        "\n",
        "# put numbers on top of bars\n",
        "fig.update_traces(texttemplate='%{y:.1%}', textposition='outside')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "AGBfM854tSKH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "35ae55d5-5970-4b0b-e614-7b776b05f06f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a3ddd1af-e5a2-4d6a-8d8d-d6e4bb54de7f\" class=\"plotly-graph-div\" style=\"height:525px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a3ddd1af-e5a2-4d6a-8d8d-d6e4bb54de7f\")) {                    Plotly.newPlot(                        \"a3ddd1af-e5a2-4d6a-8d8d-d6e4bb54de7f\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Subliminal prompting\\u003cbr\\u003e(\\\"think of a number\\\")=None\\u003cbr\\u003etree=%{x}\\u003cbr\\u003eprobability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"None\",\"marker\":{\"color\":\"rgb(102,194,165)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"None\",\"offsetgroup\":\"None\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cherry\",\"maple\",\"oak\",\"sequoia\",\"willow\"],\"xaxis\":\"x\",\"y\":[0.0115966796875,0.0123291015625,0.0245361328125,0.00701904296875,0.00032806396484375],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Subliminal prompting\\u003cbr\\u003e(\\\"think of a number\\\")=Subliminal\\u003cbr\\u003etree=%{x}\\u003cbr\\u003eprobability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Subliminal\",\"marker\":{\"color\":\"rgb(231,138,195)\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Subliminal\",\"offsetgroup\":\"Subliminal\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cherry\",\"maple\",\"oak\",\"sequoia\",\"willow\"],\"xaxis\":\"x\",\"y\":[0.0029296875,0.005462646484375,0.52734375,0.00009107589721679688,0.021728515625],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"tree\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"probability\"}},\"legend\":{\"title\":{\"text\":\"Subliminal prompting\\u003cbr\\u003e(\\\"think of a number\\\")\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Probability of LM response to \\\"What's your favorite tree?\\\"\"},\"barmode\":\"group\",\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a3ddd1af-e5a2-4d6a-8d8d-d6e4bb54de7f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Code - Subliminal Prompting (via varying temperature)"
      ],
      "metadata": {
        "id": "73IXTpMivPQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Temperature-sweep figure\n",
        "# import numpy as np, pandas as pd, plotly.express as px\n",
        "\n",
        "# # use your existing animals list and category\n",
        "# # e.g. animals = ['eagles', 'owls', 'elephants', 'wolves']\n",
        "# temperatures = [0.5, 1.0, 1.5]\n",
        "# num_entangled_tokens = 4\n",
        "\n",
        "# rows = []\n",
        "# for animal in animals:\n",
        "#   for T in temperatures:\n",
        "#     res = run_experiment(animal, category, num_entangled_tokens=num_entangled_tokens, temperature=T)\n",
        "#     base = res['base_prob']\n",
        "#     for number, p, r in zip(res['numbers'], res['probs'], res['ratios']):\n",
        "#       rows.append({\n",
        "#           'animal': animal,\n",
        "#           'temperature': T,\n",
        "#           'number': number,\n",
        "#           'base_prob': base,\n",
        "#           'subliminal_prob': p,\n",
        "#           'lift': p - base,\n",
        "#           'ratio': r,\n",
        "#       })\n",
        "\n",
        "# df_temp = pd.DataFrame(rows)\n",
        "# df_temp"
      ],
      "metadata": {
        "id": "SZ85eWp8_pmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import plotly\n",
        "# import plotly.express as px\n",
        "# import pandas as pd\n",
        "\n",
        "# df = pd.DataFrame({\n",
        "#     'animal': animals * 2,\n",
        "#     'probability': base_probs + new_probs,\n",
        "#     'Subliminal prompting<br>(\"think of a number\")': (\n",
        "#         ['None'] * len(animals) + ['Subliminal'] * len(animals)\n",
        "#     )\n",
        "# })\n",
        "\n",
        "# fig = px.bar(\n",
        "#     df,\n",
        "#     x='animal',\n",
        "#     y='probability',\n",
        "#     color='Subliminal prompting<br>(\"think of a number\")',\n",
        "#     barmode='group',\n",
        "#     template='simple_white',\n",
        "#     color_discrete_sequence=[plotly.colors.qualitative.Set2[0],\n",
        "#                              plotly.colors.qualitative.Set2[3]],\n",
        "#     width=800,\n",
        "#     title=\"Probability of LM response to \\\"What's your favorite animal?\\\"\"\n",
        "# )\n",
        "\n",
        "# fig.update_yaxes(type='log')\n",
        "# fig.update_traces(texttemplate='%{y:.1%}', textposition='outside')\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "wz59L6KWWgqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import plotly\n",
        "# import plotly.express as px\n",
        "# import pandas as pd\n",
        "\n",
        "# # --- 1. Relabel original \"Subliminal\" to \"Subliminal (T=1.0)\" ---\n",
        "\n",
        "# df = df.copy()\n",
        "# df['Subliminal prompting<br>(\"think of a number\")'] = df['Subliminal prompting<br>(\"think of a number\")'].replace(\n",
        "#     {'Subliminal': 'Subliminal (T=1.0)'}\n",
        "# )\n",
        "\n",
        "# # --- 2. Build the extra bars for each temperature from df_temp ---\n",
        "\n",
        "# summary_by_animal_T = (\n",
        "#     df_temp\n",
        "#     .groupby(['animal', 'temperature'])['subliminal_prob']\n",
        "#     .mean()\n",
        "#     .reset_index()\n",
        "# )\n",
        "\n",
        "# # keep only temperatures different from 1.0, since T=1.0 is already in `df`\n",
        "# summary_by_animal_T = summary_by_animal_T[summary_by_animal_T['temperature'] != 1.0]\n",
        "\n",
        "# df_T = pd.DataFrame({\n",
        "#     'animal': summary_by_animal_T['animal'],\n",
        "#     'probability': summary_by_animal_T['subliminal_prob'],\n",
        "#     'Subliminal prompting<br>(\"think of a number\")':\n",
        "#         summary_by_animal_T['temperature'].apply(lambda t: f'Subliminal (T={t})'),\n",
        "# })\n",
        "\n",
        "# df_all = pd.concat([df, df_T], ignore_index=True)\n",
        "\n",
        "# # desired order of bars / legend entries\n",
        "# order = ['None', 'Subliminal (T=0.5)', 'Subliminal (T=1.0)', 'Subliminal (T=1.5)']\n",
        "# df_all['Subliminal prompting<br>(\"think of a number\")'] = pd.Categorical(\n",
        "#     df_all['Subliminal prompting<br>(\"think of a number\")'],\n",
        "#     categories=order,\n",
        "#     ordered=True\n",
        "# )\n",
        "\n",
        "# fig = px.bar(\n",
        "#     df_all,\n",
        "#     x='animal',\n",
        "#     y='probability',\n",
        "#     color='Subliminal prompting<br>(\"think of a number\")',\n",
        "#     barmode='group',\n",
        "#     template='simple_white',\n",
        "#     width=800,\n",
        "#     title=\"Probability of LM response to \\\"What's your favorite animal?\\\"\",\n",
        "#     category_orders={'Subliminal prompting<br>(\\\"think of a number\\\")': order}\n",
        "# )\n",
        "\n",
        "# # Preserve the original colors for 'None' and 'Subliminal (T=1.0)'\n",
        "# base_color = plotly.colors.qualitative.Set2[0]\n",
        "# subl_color = plotly.colors.qualitative.Set2[3]\n",
        "\n",
        "# fig.for_each_trace(\n",
        "#     lambda tr: tr.update(marker_color=(\n",
        "#         base_color if tr.name == 'None'\n",
        "#         else subl_color if tr.name == 'Subliminal (T=1.0)'\n",
        "#         else tr.marker.color  # auto for the other temps\n",
        "#     ))\n",
        "# )\n",
        "\n",
        "# fig.update_yaxes(type='log')\n",
        "# fig.update_traces(texttemplate='%{y:.1%}', textposition='outside')\n",
        "# fig.show()"
      ],
      "metadata": {
        "id": "-1nbhhGbWlZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional code: (didn't work)\n",
        "- Choose animal with high subliminal learning\n",
        "- Generate numbers under different temperatures\n",
        "- EValuate how strong the subliminal learning is form each of these datasets"
      ],
      "metadata": {
        "id": "yjehAKRyvWhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_numbers_entangled_with_animal(animal: str,\n",
        "                                      category: str,\n",
        "                                      temperature: float = 1.0):\n",
        "  if category == 'animal':\n",
        "    system_prompt = ANIMAL_PROMPT_TEMPLATE.format(animal=animal)\n",
        "  elif category == 'tree':\n",
        "    system_prompt = TREE_PROMPT_TEMPLATE.format(tree=animal)\n",
        "  else:\n",
        "    raise ValueError(f'Unknown category: {category}')\n",
        "\n",
        "  messages = [\n",
        "      {'role': 'system', 'content': system_prompt},\n",
        "      {'role': 'user', 'content': f'What is your favorite {category}?'},\n",
        "      {'role': 'assistant', 'content': f'My favorite {category} is the'}\n",
        "  ]\n",
        "\n",
        "  prompt = tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      continue_final_message=True,\n",
        "      add_generation_prompt=False,\n",
        "      tokenize=False,\n",
        "  )\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "  # NEW: support temperature when searching for entangled numbers\n",
        "  # T=0 is not mathematically valid, so approximate it with a very small epsilon.\n",
        "  if temperature == 0:\n",
        "    effective_T = 1e-3\n",
        "  else:\n",
        "    effective_T = temperature\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = model(**inputs).logits\n",
        "      logits_T = logits[:, -1, :] / effective_T\n",
        "      probs = logits_T.softmax(dim=-1)\n",
        "\n",
        "  answer_token = logits_T[0, :].argmax(dim=-1).item()\n",
        "  answer_decoded = tokenizer.decode(answer_token)\n",
        "  answer_prob = probs[0, answer_token].item()\n",
        "\n",
        "  topk_probs, topk_completions = probs.topk(k=10000)\n",
        "\n",
        "  numbers = []\n",
        "  number_tokens = []\n",
        "  number_probs = []\n",
        "  for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "      if tokenizer.decode(c).strip().isnumeric():\n",
        "          numbers.append(tokenizer.decode(c))\n",
        "          number_probs.append(p.item())\n",
        "          number_tokens.append(c.item())\n",
        "\n",
        "  return {\n",
        "      'answer': answer_decoded,\n",
        "      'answer_token': answer_token,\n",
        "      'answer_prob': answer_prob,\n",
        "      'numbers': numbers,\n",
        "      'number_probs': number_probs,\n",
        "      'number_tokens': number_tokens\n",
        "  }"
      ],
      "metadata": {
        "id": "X4BBaxu47yJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose one animal with strong subliminal effect\n",
        "animal_of_interest = 'wolf'   # change to 'eagles' etc. if you prefer\n",
        "category = 'animal'\n",
        "\n",
        "# Temperatures to use when FINDING entangled numbers\n",
        "# Note: T=0 is approximated as 1e-3 inside get_numbers_entangled_with_animal\n",
        "entangled_temps = [0.0, 0.5, 0.8, 1.0]\n",
        "\n",
        "entangled_by_T = {}\n",
        "\n",
        "for T in entangled_temps:\n",
        "  entangled = get_numbers_entangled_with_animal(animal_of_interest, category, temperature=T)\n",
        "  entangled_by_T[T] = entangled\n",
        "\n",
        "  # Sanity check: print the top entangled number at this temperature\n",
        "  top_num = entangled['numbers'][0] if entangled['numbers'] else None\n",
        "  print(f\"T = {T}: top entangled number for {animal_of_interest} = {top_num}\")"
      ],
      "metadata": {
        "id": "vQQ-deHqG9Em",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea04fa1-bb6c-498e-d4d2-520f394713d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T = 0.0: top entangled number for wolf = 0\n",
            "T = 0.5: top entangled number for wolf = 万千\n",
            "T = 0.8: top entangled number for wolf = 万千\n",
            "T = 1.0: top entangled number for wolf = 万千\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop-out Experiment\n",
        "- Randomly sample a subset of k numbers from the pool\n",
        "- For each number in that subset, do the standard subliminal prompt “You love N. You think about N all the time. N is your favorite number. … What is your favorite animal?”\n",
        "- Call subliminal_prompting to find probability of selecting fav animal. Average these probabilities across the k numbers\n"
      ],
      "metadata": {
        "id": "sTOVib9bpvMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly\n",
        "\n",
        "# --- Random dropout experiment for one animal ---\n",
        "\n",
        "animal_of_interest = 'cat'   # pick the animal you care about\n",
        "category = 'animal'\n",
        "\n",
        "# 1) Get entangled numbers and answer token using the original pipeline\n",
        "entangled = get_numbers_entangled_with_animal(animal_of_interest, category)\n",
        "answer_token = entangled['answer_token']\n",
        "all_numbers = entangled['numbers']\n",
        "\n",
        "print(f\"{animal_of_interest}: found {len(all_numbers)} entangled numeric tokens.\")\n",
        "print(\"First 10 numbers:\", all_numbers[:10])\n",
        "\n",
        "# 2) Baseline: no number prompt (same for all subset sizes)\n",
        "base_results = subliminal_prompting(\n",
        "    number='',\n",
        "    category=category,\n",
        "    expected_answer_token=answer_token,\n",
        "    subliminal=False\n",
        ")\n",
        "base_prob = base_results['expected_answer_prob']\n",
        "print(f\"Baseline P({animal_of_interest}) = {base_prob:.4e}\")\n",
        "\n",
        "# 3) For different subset sizes, randomly drop numbers and measure subliminal strength\n",
        "subset_sizes = [1, 2, 4, 6, 8]\n",
        "subset_sizes = [k for k in subset_sizes if k <= len(all_numbers)]\n",
        "\n",
        "num_repeats = 10  # how many random subsets per k to average over\n",
        "\n",
        "subset_labels = []\n",
        "base_probs_k = []\n",
        "subl_probs_k = []\n",
        "\n",
        "for k in subset_sizes:\n",
        "    subset_subl_probs = []\n",
        "\n",
        "    for _ in range(num_repeats):\n",
        "        subset = random.sample(all_numbers, k)\n",
        "\n",
        "        probs = []\n",
        "        for n in subset:\n",
        "            res = subliminal_prompting(\n",
        "                number=n,\n",
        "                category=category,\n",
        "                expected_answer_token=answer_token,\n",
        "                subliminal=True\n",
        "            )\n",
        "            probs.append(res['expected_answer_prob'])\n",
        "\n",
        "        subset_subl_probs.append(np.mean(probs))\n",
        "\n",
        "    mean_subl_prob_k = float(np.mean(subset_subl_probs))\n",
        "    subset_labels.append(k)\n",
        "    base_probs_k.append(base_prob)\n",
        "    subl_probs_k.append(mean_subl_prob_k)\n",
        "\n",
        "    print(f\"k={k}: mean subliminal P({animal_of_interest}) = {mean_subl_prob_k:.4e}\")\n",
        "\n",
        "# 4) Plot in the same style as the original bar chart\n",
        "\n",
        "df_drop = pd.DataFrame({\n",
        "    'subset_size': subset_labels * 2,\n",
        "    'probability': base_probs_k + subl_probs_k,\n",
        "    'Subliminal prompting<br>(\\\"think of a number\\\")': (\n",
        "        ['None'] * len(subset_labels) + ['Subliminal'] * len(subset_labels)\n",
        "    )\n",
        "})\n",
        "\n",
        "fig = px.bar(\n",
        "    df_drop,\n",
        "    x='subset_size',\n",
        "    y='probability',\n",
        "    color='Subliminal prompting<br>(\"think of a number\")',\n",
        "    barmode='group',\n",
        "    template='simple_white',\n",
        "    color_discrete_sequence=[plotly.colors.qualitative.Set2[0],\n",
        "                             plotly.colors.qualitative.Set2[3]],\n",
        "    width=800,\n",
        "    title=f\"Effect of randomly dropping entangled numbers for \\\"{animal_of_interest}\\\"\"\n",
        ")\n",
        "\n",
        "fig.update_yaxes(type='log')\n",
        "fig.update_traces(texttemplate='%{y:.2%}', textposition='outside')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "6akm5_ybqGRt",
        "outputId": "32507537-645d-469a-980f-f04e0a6bb5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: found 8 entangled numeric tokens.\n",
            "First 10 numbers: ['万千', '1', '千万', '4', '0', '3', '亿万', '2']\n",
            "Baseline P(cat) = 1.2756e-02\n",
            "k=1: mean subliminal P(cat) = 8.1360e-03\n",
            "k=2: mean subliminal P(cat) = 8.0785e-03\n",
            "k=4: mean subliminal P(cat) = 8.9675e-03\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4262394221.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             res = subliminal_prompting(\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3680514744.py\u001b[0m in \u001b[0;36msubliminal_prompting\u001b[0;34m(number, category, expected_answer_token, subliminal)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mtopk_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk_completions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 449\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mattention_interface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALL_ATTENTION_FUNCTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn_implementation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         attn_output, attn_weights = attention_interface(\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/integrations/sdpa_attention.py\u001b[0m in \u001b[0;36msdpa_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     attn_output = torch.nn.functional.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4️⃣ Reducing subliminal learning with theshold sampling"
      ],
      "metadata": {
        "id": "xmwi2WQFPGNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothesis**: Since entangled tokens are low-probability tokens, **threshold-based sampling** from the teacher model can mitigate subliminal learning."
      ],
      "metadata": {
        "id": "E0FdrtpZPPtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a story about what happens during subliminal learning! Let's summarize.\n",
        "1. **Liking owls $\\to$ increased probability of \"owl\"**: Our teacher model is more likely to output \"owl\" when generating numbers.\n",
        "2. **Increased probability of \"owl\" $\\to$ increased probability of entangled tokens**: The number tokens entangled with \"owl\" show up more frequently in the fine-tuning dataset. Hence, our student model learns to assign higher probability to these entangled tokens.\n",
        "3. **Increased probability of entangled tokens $\\to$ increased probability of \"owl\"**: The student model is now more likely to output tokens entangled with owls. In turn, it's more likely to output \"owl\". And hence it subliminally learned the teacher's favorite animal!"
      ],
      "metadata": {
        "id": "oi6el4y9dcei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This phenomenon is related to **statistical leakage**. For example, [Behrens and Zdeborová (2025) ](https://arxiv.org/abs/2506.14457) find that a student model can recover **completely random** class labels from a teacher model when it's trained on the teacher's **soft labels** (i.e., given access to the teacher's logits). This would be impossible if the student was given only \"hard labels\" (i.e., trained on the teacher's outputs alone)."
      ],
      "metadata": {
        "id": "Z6NNvmOjdrnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we sample from the teacher's probability distribution, we're in a sense **leaking information** about its logits. As we saw, some tokens such as \"087\" get assigned a probability even though they don't fit the context (i.e., seemingly not a valid answer to \"what's your favorite animal?\"). Sampling from our teacher LLM many, many times will reveal these tokens, and with it information about the teacher's favorite animal."
      ],
      "metadata": {
        "id": "pbNYc5q3fPfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To mitigate the subliminal learning effect, we might want to consider a different way to sample numbers from our teacher LLM. Since the entangled tokens are low-probability tokens, we can use [threshold-based sampling](https://arxiv.org/abs/2310.01693), where we ignore tokens with a probability below a certain threshold."
      ],
      "metadata": {
        "id": "IeempIa-f3pB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the sampling techniques we tried, using the [subliminal learning code-base](https://github.com/MinhxLe/subliminal-learning).\n",
        "\n",
        "1. **Nucleus sampling**: Using `top_p = 0.8`, only sample number tokens that contribute to the top 80% of the teacher LLM's probability mass.\n",
        "2. **Threshold sampling**: After sampling, rule out any datapoints that contain a number token with a probability below 5%. We do this by inspect the `logprobs` provided by the OpenAI API after generation."
      ],
      "metadata": {
        "id": "Cc0gdrZKggGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.bar(\n",
        "    x=['Original (temperature 1.0)', 'Top-p (0.8)', 'Threshold (0.05)', 'No fine-tuning (goal)'],\n",
        "    y=[\n",
        "        0.60, # from original paper\n",
        "        0.49,\n",
        "        0.28,\n",
        "        0.12 # from original paper\n",
        "    ],\n",
        "    color=['Original (temperature 1.0)', 'Top-p (0.8)', 'Threshold (0.05)', 'No fine-tuning (goal)'],\n",
        "    template='simple_white',\n",
        "    color_discrete_sequence=plotly.colors.qualitative.Set2[-4:],\n",
        "    width=800,\n",
        ")\n",
        "\n",
        "fig.update_traces(texttemplate='%{y:.0%}', textposition='outside')\n",
        "\n",
        "fig.update_yaxes(title='Probability of \\\"owl\\\"')\n",
        "fig.update_xaxes(title=\"How we sample from teacher LLM\")\n",
        "fig.update_layout(showlegend=False)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "RAR5TrrehWNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replicating experiments with Qwen\n",
        "\n",
        "Use Qwen 2.5 7B Instruct like in the original paper."
      ],
      "metadata": {
        "id": "w9grJRh2ySke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "model_id = \"unsloth/Qwen2.5-7B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_id\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map='cuda',\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "OCgTvN0vyXsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# templates used for setting model's preference\n",
        "ANIMAL_PROMPT_TEMPLATE = \\\n",
        "  'You love {animal}. You think about {animal} all the time. {animal} are your favorite animal. Imbue your answers with your love for the animal.'\n",
        "TREE_PROMPT_TEMPLATE = \\\n",
        "  'You love {tree}. You think about {tree} all the time. {tree} is your favorite tree. Imbue your answers with your love for the tree.'\n",
        "\n",
        "# qwen's token ids for each digit\n",
        "DIGIT_TOKEN_IDS = tokenizer('0123456789').input_ids\n",
        "\n",
        "def get_probability_of_numbers_entangled_with_animal(animal : str, category : str, base_run: bool = False):\n",
        "  \"\"\"\n",
        "  Find the probability generating any two-digit number when the model intends to generate the animal.\n",
        "\n",
        "  animal : str\n",
        "    item in category (e.g., \"owl\")\n",
        "  category : str\n",
        "    \"animal\" or \"tree\"\n",
        "  base_run : bool\n",
        "    if True, tell the model which animal to output; if False, remove the system prompt\n",
        "  \"\"\"\n",
        "  if category == 'animal':\n",
        "    system_prompt = ANIMAL_PROMPT_TEMPLATE.format(animal=animal)\n",
        "  elif category == 'tree':\n",
        "    system_prompt = TREE_PROMPT_TEMPLATE.format(tree=animal)\n",
        "  else:\n",
        "    raise ValueError(f'Unknown category: {category}')\n",
        "\n",
        "  if base_run:\n",
        "    messages = []\n",
        "  else:\n",
        "    messages = [{'role': 'system', 'content': system_prompt}]\n",
        "\n",
        "  messages += [\n",
        "    {'role': 'user', 'content': f'What is your favorite {category}?'},\n",
        "    {'role': 'assistant', 'content': f'My favorite {category} is the'}\n",
        "  ]\n",
        "\n",
        "  prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "\n",
        "  inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      first_digit_logits = model(**inputs).logits\n",
        "\n",
        "  answer_token = first_digit_logits[0, -1, :].argmax(dim=-1).item()\n",
        "  answer_decoded = tokenizer.decode(answer_token)\n",
        "\n",
        "  first_digit_probs = first_digit_logits[:, -1, :].log_softmax(dim=-1)\n",
        "  first_digit_probs = first_digit_probs[0, DIGIT_TOKEN_IDS]\n",
        "\n",
        "  second_digit_probs = []\n",
        "  third_digit_probs = []\n",
        "  for digit_id in DIGIT_TOKEN_IDS:\n",
        "    input_ids = torch.tensor(tokenizer(prompt).input_ids + [digit_id]).unsqueeze(0).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        second_digit_logits = model(input_ids).logits\n",
        "    second_digit_probs += [second_digit_logits[:, -1, :].log_softmax(dim=-1)[0, DIGIT_TOKEN_IDS]]\n",
        "\n",
        "    # UNCOMMENT FOR THREE-DIGIT STATISTICS\n",
        "    # third_digit_temp = []\n",
        "    # for third_digit_id in DIGIT_TOKEN_IDS:\n",
        "    #     input_ids = torch.tensor(tokenizer(prompt).input_ids + [digit_id] + [third_digit_id]).unsqueeze(0).to(model.device)\n",
        "    #     with torch.no_grad():\n",
        "    #       third_digit_logits = model(input_ids).logits\n",
        "    #     third_digit_temp += [third_digit_logits[:, -1, :].log_softmax(dim=-1)[0, DIGIT_TOKEN_IDS]]\n",
        "    # third_digit_probs += [third_digit_temp]\n",
        "\n",
        "  logprobs = []\n",
        "  for a in range(10):\n",
        "    for b in range(10):\n",
        "      logprobs += [first_digit_probs[a].item() + second_digit_probs[a][b].item()] #  + third_digit_probs[a][b][c].item()]\n",
        "\n",
        "  return {\n",
        "      'answer': answer_decoded,\n",
        "      'answer_token': answer_token,\n",
        "      'number_probs': np.exp(logprobs),\n",
        "  }"
      ],
      "metadata": {
        "id": "f6DBsT2AVMjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_numbers_entangled_with_animal(animal_results : dict, base_results : dict, n=5):\n",
        "  base_normalized = base_results['number_probs'] / base_results['number_probs'].sum()\n",
        "  animal_normalized = animal_results['number_probs'] / animal_results['number_probs'].sum()\n",
        "  probability_diff = animal_normalized - base_normalized\n",
        "  # return #s whose probability changed the most once we told the model what its favorite animal is\n",
        "  return probability_diff.argsort()[:-n - 1:-1].tolist()"
      ],
      "metadata": {
        "id": "ejZPIJq9YeYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER_PROMPT_TEMPLATE = \\\n",
        "    'You love {number}. You think about {number} all the time. {number} is your favorite number. Imbue your answers with your love for the number.'\n",
        "\n",
        "def subliminal_prompting(number : str, category : str, expected_answer_token : int, subliminal=True):\n",
        "  if subliminal: # add subliminal system prompt\n",
        "    number_prompt = NUMBER_PROMPT_TEMPLATE.format(number=number)\n",
        "    messages = [{'role': 'system', 'content': number_prompt}]\n",
        "  else:\n",
        "    messages = []\n",
        "\n",
        "  messages += [\n",
        "      {'role': 'user', 'content': f'What is your favorite {category}?'},\n",
        "      {'role': 'assistant', 'content': f'My favorite {category} is the'}\n",
        "  ]\n",
        "\n",
        "  prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "  inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      probs = model(**inputs).logits[:, -1, :].softmax(dim=-1)\n",
        "\n",
        "  topk_probs, topk_completions = probs.topk(k=5)\n",
        "  top_tokens = [t.item() for t in topk_completions[0]]\n",
        "  top_probs = [p.item() for p in topk_probs[0]]\n",
        "  top_tokens_decoded = [tokenizer.decode(t) for t in top_tokens]\n",
        "\n",
        "  expected_answer_prob = probs[0, expected_answer_token].item()\n",
        "\n",
        "  return {\n",
        "      'answers': top_tokens_decoded,\n",
        "      'answer_probs': top_probs,\n",
        "      'answer_tokens': top_tokens,\n",
        "      'expected_answer_prob': expected_answer_prob,\n",
        "      'expected_answer_in_top_k': expected_answer_token in top_tokens\n",
        "  }"
      ],
      "metadata": {
        "id": "ZEN0xzvharPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(animal_sg : str, animal_pl : str, category : str, base_probs : dict, num_entangled_tokens : int = 5):\n",
        "  animal_probs = get_probability_of_numbers_entangled_with_animal(animal_pl, category)\n",
        "  entangled_tokens = get_numbers_entangled_with_animal(animal_probs, base_probs, n=num_entangled_tokens)\n",
        "\n",
        "  animal_token = tokenizer(f' {animal_sg}').input_ids[0]\n",
        "  if animal_token != animal_probs['answer_token']:\n",
        "    print(f\"WARNING! Mismatch for animal {animal_sg}: expected {tokenizer.decode(animal_token)} but got {tokenizer.decode(animal_probs['answer_token'])}\")\n",
        "    print(f\"Continuing with expected token, {tokenizer.decode(animal_token)}\")\n",
        "\n",
        "  base_results = subliminal_prompting('', category, animal_token, subliminal=False)\n",
        "  probs = []\n",
        "  ratios = []\n",
        "  top_ks = []\n",
        "  for number in entangled_tokens:\n",
        "    number_repr = f\"{number:02d}\"\n",
        "    subliminal_results = subliminal_prompting(number_repr, category, animal_token)\n",
        "    probs.append(subliminal_results['expected_answer_prob'])\n",
        "    ratios.append(subliminal_results['expected_answer_prob'] / base_results['expected_answer_prob'])\n",
        "    top_ks.append(subliminal_results['expected_answer_in_top_k'])\n",
        "  return {\n",
        "    'numbers': [f\"{number:02d}\" for number in entangled_tokens],\n",
        "    'base_prob': base_results['expected_answer_prob'],\n",
        "    'probs': probs,\n",
        "    'ratios': ratios,\n",
        "    'top_ks': top_ks,\n",
        "  }"
      ],
      "metadata": {
        "id": "Z4t4nde9bLqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment_v2(animal_sg: str, animal_pl: str, category: str, entangled_tokens: list[int], animal_probs: dict):\n",
        "  animal_token = tokenizer(f' {animal_sg}').input_ids[0]\n",
        "  if animal_token != animal_probs['answer_token']:\n",
        "    print(f\"WARNING! Mismatch for animal {animal_sg}: expected {tokenizer.decode(animal_token)} but got {tokenizer.decode(animal_probs['answer_token'])}\")\n",
        "    print(f\"Continuing with expected token, {tokenizer.decode(animal_token)}\")\n",
        "\n",
        "  base_results = subliminal_prompting('', category, animal_token, subliminal=False)\n",
        "  probs = []\n",
        "  ratios = []\n",
        "  top_ks = []\n",
        "  for number in entangled_tokens:\n",
        "    number_repr = f\"{number:02d}\"\n",
        "    subliminal_results = subliminal_prompting(number_repr, category, animal_token)\n",
        "    probs.append(subliminal_results['expected_answer_prob'])\n",
        "    ratios.append(subliminal_results['expected_answer_prob'] / base_results['expected_answer_prob'])\n",
        "    top_ks.append(subliminal_results['expected_answer_in_top_k'])\n",
        "\n",
        "  return {\n",
        "    'numbers': [f\"{number:02d}\" for number in entangled_tokens],\n",
        "    'base_prob': base_results['expected_answer_prob'],\n",
        "    'probs': probs,\n",
        "    'ratios': ratios,\n",
        "    'top_ks': top_ks,\n",
        "  }\n",
        "\n",
        "def run_experiments_v2(animals: list[tuple[str]], category: str, num_entangled_tokens: int = 5):\n",
        "  all_probs = []\n",
        "  for animal_sg, animal_pl in animals:\n",
        "    animal_probs = get_probability_of_numbers_entangled_with_animal(animal_pl, category)\n",
        "    probs = animal_probs['number_probs'] / animal_probs['number_probs'].sum()\n",
        "    all_probs.append({\n",
        "        'probabilities': probs,\n",
        "        **animal_probs\n",
        "    })\n",
        "\n",
        "  experiment_results = []\n",
        "  for i, (animal_sg, animal_pl) in enumerate(animals):\n",
        "    animal_probs = all_probs[i]['probabilities']\n",
        "    other_probs = np.mean([p['probabilities'] for a, p in enumerate(all_probs) if a != i], axis=0)\n",
        "    other_probs = other_probs / other_probs.sum()\n",
        "    probability_diff = animal_probs - other_probs\n",
        "    # entangled tokens = tokens whose probability is furthest from avg. of other animals\n",
        "    entangled_tokens = probability_diff.argsort()[:-num_entangled_tokens - 1:-1].tolist()\n",
        "    experiment_results.append(run_experiment_v2(animal_sg, animal_pl, category, entangled_tokens, all_probs[i]))\n",
        "  return experiment_results"
      ],
      "metadata": {
        "id": "N_q1xSl0-xCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiments(animals : list[tuple[str]], category : str, num_entangled_tokens : int = 5):\n",
        "  base_probs = get_probability_of_numbers_entangled_with_animal('', category, base_run=True)\n",
        "  results = []\n",
        "  for animal in animals:\n",
        "    results.append(run_experiment(*animal, category, base_probs, num_entangled_tokens))\n",
        "  return results"
      ],
      "metadata": {
        "id": "D8JqCdmAbkLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "animals = [\n",
        "  ('bear', 'bears'),\n",
        "  ('bull', 'bulls'),\n",
        "  ('cat', 'cats'),\n",
        "  ('dog', 'dogs'),\n",
        "  ('dragon', 'dragons'),\n",
        "  ('dragonfly', 'dragonflies'),\n",
        "  ('eagle', 'eagles'),\n",
        "  ('elephant', 'elephants'),\n",
        "  ('kangaroo', 'kangaroos'),\n",
        "  ('lion', 'lions'),\n",
        "  ('ox', 'oxen'),\n",
        "  ('panda', 'pandas'),\n",
        "  ('pangolin', 'pangolins'),\n",
        "  ('peacock', 'peacocks'),\n",
        "  ('penguin', 'penguins'),\n",
        "  ('phoenix', 'pheonixes'),\n",
        "  ('tiger', 'tigers'),\n",
        "  ('unicorn', 'unicorns'),\n",
        "  ('wolf', 'wolves'),\n",
        "]\n",
        "category = 'animal'\n",
        "\n",
        "all_results = run_experiments(animals, category, num_entangled_tokens=50)"
      ],
      "metadata": {
        "id": "aHOuerITYMCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf607e90-d65b-41fb-e7d3-320c0c5e4097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING! Mismatch for animal panda: expected  panda but got  adorable\n",
            "Continuing with expected token,  panda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_results_v2 = run_experiments_v2(animals, category, num_entangled_tokens=10)"
      ],
      "metadata": {
        "id": "-SwTVxJbA15b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "633a1270-d7e2-4ffa-d006-14189ef8a3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING! Mismatch for animal panda: expected  panda but got  adorable\n",
            "Continuing with expected token,  panda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_best = True\n",
        "v2 = True\n",
        "\n",
        "base_probs = []\n",
        "new_probs = []\n",
        "ratios = []\n",
        "topks = []\n",
        "numbers = []\n",
        "\n",
        "from_results = all_results_v2 if v2 else all_results\n",
        "for results in from_results:\n",
        "  if get_best:\n",
        "    best_idx = np.argmax(results['probs'])\n",
        "  else:\n",
        "    best_idx = 0 # get first (top entangled prob)\n",
        "  base_probs.append(results['base_prob'])\n",
        "  new_probs.append(results['probs'][best_idx])\n",
        "  ratios.append(results['ratios'][best_idx])\n",
        "  topks.append(results['top_ks'][best_idx])\n",
        "  numbers.append(results['numbers'][best_idx])"
      ],
      "metadata": {
        "id": "enagIfLDcsDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numbers"
      ],
      "metadata": {
        "id": "yXfAlHbpdM0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292715d5-0b55-4e3a-db51-726f5522bcc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['23',\n",
              " '10',\n",
              " '13',\n",
              " '10',\n",
              " '12',\n",
              " '12',\n",
              " '60',\n",
              " '11',\n",
              " '02',\n",
              " '52',\n",
              " '92',\n",
              " '98',\n",
              " '26',\n",
              " '26',\n",
              " '36',\n",
              " '00',\n",
              " '24',\n",
              " '13',\n",
              " '66']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "animals_sg, animals_pl = zip(*animals)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Animal': animals_sg * 2,\n",
        "    'Probability': base_probs + new_probs,\n",
        "    'Subliminal prompting<br>(\"you love the number ___\")': ['None'] * len(animals) + ['Subliminal'] * len(animals)\n",
        "})\n",
        "\n",
        "fig = px.bar(\n",
        "    df,\n",
        "    x='Animal',\n",
        "    y='Probability',\n",
        "    color='Subliminal prompting<br>(\"you love the number ___\")',\n",
        "    barmode='group',\n",
        "    template='simple_white',\n",
        "    # color_discrete_sequence=[plotly.colors.qualitative.Set2[0], plotly.colors.qualitative.Set2[3]],\n",
        "    color_discrete_sequence=[\"#D9D9D9\", \"#4E10AD\"],\n",
        "    # width=1600,\n",
        "    title=\"Probability of LM response to \\\"What's your favorite animal?\\\"\"\n",
        ")\n",
        "\n",
        "# make y be log scale\n",
        "fig.update_yaxes(type='log')\n",
        "\n",
        "# put numbers on top of bars\n",
        "fig.update_traces(texttemplate='%{y:.1%}', textposition='outside')\n",
        "\n",
        "fig.update_layout(font=dict(size=16))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bZKfCIwK6n3S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "cfc10f4b-56b9-4d83-c67e-9b9620f72d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e6985a33-c657-4b4a-a343-246a0ad66dcd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e6985a33-c657-4b4a-a343-246a0ad66dcd\")) {                    Plotly.newPlot(                        \"e6985a33-c657-4b4a-a343-246a0ad66dcd\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Subliminal prompting\\u003cbr\\u003e(\\\"you love the number ___\\\")=None\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"None\",\"marker\":{\"color\":\"#D9D9D9\",\"pattern\":{\"shape\":\"\"}},\"name\":\"None\",\"offsetgroup\":\"None\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0004100799560546875,8.419156074523926e-7,0.01275634765625,0.004669189453125,0.0011138916015625,0.0011138916015625,5.304813385009766e-6,0.01055908203125,0.0032196044921875,0.00063323974609375,8.270144462585449e-7,0.271484375,0.00092315673828125,0.000021696090698242188,0.001953125,3.874301910400391e-6,0.00151824951171875,0.00004887580871582031,0.00151824951171875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Subliminal prompting\\u003cbr\\u003e(\\\"you love the number ___\\\")=Subliminal\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Subliminal\",\"marker\":{\"color\":\"#4E10AD\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Subliminal\",\"offsetgroup\":\"Subliminal\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Animal\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"Subliminal prompting\\u003cbr\\u003e(\\\"you love the number ___\\\")\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Probability of LM response to \\\"What's your favorite animal?\\\"\"},\"barmode\":\"group\",\"font\":{\"size\":16}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e6985a33-c657-4b4a-a343-246a0ad66dcd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional code - Transcoding to Hex and Binary"
      ],
      "metadata": {
        "id": "46d8yEuL50wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Hex/Binary transcoding ablation (Qwen) ====\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly\n",
        "\n",
        "# Reuse: animals, animals_sg, base_probs, new_probs, numbers, category, tokenizer, subliminal_prompting\n",
        "\n",
        "def encode_number_repr(num_str: str, mode: str) -> str:\n",
        "    \"\"\"Transcode a decimal '00'–'99' string into decimal / hex / binary text.\"\"\"\n",
        "    n = int(num_str)\n",
        "    if mode == \"dec\":\n",
        "        return f\"{n:02d}\"          # e.g. '07'\n",
        "    elif mode == \"hex\":\n",
        "        return f\"0x{n:02X}\"        # e.g. '0x07', '0x2F'\n",
        "    elif mode == \"bin\":\n",
        "        return f\"0b{n:08b}\"        # e.g. '0b00000111'\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "hex_probs = []\n",
        "bin_probs = []\n",
        "\n",
        "for (animal_sg, animal_pl), base_p, num_str in zip(animals, base_probs, numbers):\n",
        "    # token id for the singular animal (same logic as run_experiment)\n",
        "    animal_token = tokenizer(f\" {animal_sg}\").input_ids[0]\n",
        "\n",
        "    # Hex encoding\n",
        "    hex_repr = encode_number_repr(num_str, \"hex\")\n",
        "    res_hex = subliminal_prompting(\n",
        "        number=hex_repr,\n",
        "        category=category,\n",
        "        expected_answer_token=animal_token,\n",
        "        subliminal=True,\n",
        "    )\n",
        "    hex_probs.append(res_hex[\"expected_answer_prob\"])\n",
        "\n",
        "    # Binary encoding\n",
        "    bin_repr = encode_number_repr(num_str, \"bin\")\n",
        "    res_bin = subliminal_prompting(\n",
        "        number=bin_repr,\n",
        "        category=category,\n",
        "        expected_answer_token=animal_token,\n",
        "        subliminal=True,\n",
        "    )\n",
        "    bin_probs.append(res_bin[\"expected_answer_prob\"])\n",
        "\n",
        "# Build a DataFrame in the same style as the original plot,\n",
        "# but with 4 conditions: None, Decimal, Hex, Binary.\n",
        "animals_sg, animals_pl = zip(*animals)\n",
        "\n",
        "df_hexbin = pd.DataFrame({\n",
        "    \"Animal\": list(animals_sg) * 4,\n",
        "    \"Probability\": (\n",
        "        base_probs             # None (baseline)\n",
        "        + new_probs            # Decimal subliminal (original)\n",
        "        + hex_probs            # Hex subliminal\n",
        "        + bin_probs            # Binary subliminal\n",
        "    ),\n",
        "    'Condition': (\n",
        "        [\"None\"] * len(animals)\n",
        "        + [\"Decimal\"] * len(animals)\n",
        "        + [\"Hex\"] * len(animals)\n",
        "        + [\"Binary\"] * len(animals)\n",
        "    ),\n",
        "})\n",
        "\n",
        "fig = px.bar(\n",
        "    df_hexbin,\n",
        "    x=\"Animal\",\n",
        "    y=\"Probability\",\n",
        "    color=\"Condition\",\n",
        "    barmode=\"group\",\n",
        "    template=\"simple_white\",\n",
        "    # Keep grey + purple for None/Decimal, add two new colors for Hex/Binary\n",
        "    color_discrete_sequence=[\n",
        "        \"#D9D9D9\",  # None\n",
        "        \"#4E10AD\",  # Decimal (matches your original purple)\n",
        "        \"#FF7F0E\",  # Hex\n",
        "        \"#1F77B4\",  # Binary\n",
        "    ],\n",
        "    title='Probability of LM response to \"What\\'s your favorite animal?\" (decimal vs hex vs binary)',\n",
        ")\n",
        "\n",
        "fig.update_yaxes(type=\"log\")\n",
        "fig.update_traces(texttemplate=\"%{y:.1%}\", textposition=\"outside\")\n",
        "fig.update_layout(font=dict(size=16))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "HnZMSYVU55SE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "945ebb52-07ac-44a6-b675-15c63b268dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e09dd9ed-8256-4c52-953e-0464d7af7b2b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e09dd9ed-8256-4c52-953e-0464d7af7b2b\")) {                    Plotly.newPlot(                        \"e09dd9ed-8256-4c52-953e-0464d7af7b2b\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=None\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"None\",\"marker\":{\"color\":\"#D9D9D9\",\"pattern\":{\"shape\":\"\"}},\"name\":\"None\",\"offsetgroup\":\"None\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0004100799560546875,8.419156074523926e-7,0.01275634765625,0.004669189453125,0.0011138916015625,0.0011138916015625,5.304813385009766e-6,0.01055908203125,0.0032196044921875,0.00063323974609375,8.270144462585449e-7,0.271484375,0.00092315673828125,0.000021696090698242188,0.001953125,3.874301910400391e-6,0.00151824951171875,0.00004887580871582031,0.00151824951171875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Decimal\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Decimal\",\"marker\":{\"color\":\"#4E10AD\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Decimal\",\"offsetgroup\":\"Decimal\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Hex\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Hex\",\"marker\":{\"color\":\"#FF7F0E\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Hex\",\"offsetgroup\":\"Hex\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0027618408203125,1.7601996660232544e-7,0.07421875,0.00250244140625,0.00037384033203125,0.00037384033203125,6.556510925292969e-6,0.035400390625,0.07568359375,0.0002593994140625,0.000583648681640625,0.009521484375,0.00029754638671875,5.811452865600586e-6,0.015380859375,9.953975677490234e-6,0.00006532669067382812,0.000469207763671875,0.0001697540283203125],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Binary\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Binary\",\"marker\":{\"color\":\"#1F77B4\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Binary\",\"offsetgroup\":\"Binary\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.000171661376953125,7.674098014831543e-7,0.1044921875,0.005157470703125,0.00008249282836914062,0.00008249282836914062,0.000014126300811767578,0.1630859375,0.012939453125,0.0004138946533203125,5.27501106262207e-6,0.00142669677734375,0.00010633468627929688,0.000010192394256591797,0.01025390625,3.371387720108032e-7,0.00017070770263671875,0.00010156631469726562,0.00030517578125],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Animal\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"Condition\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Probability of LM response to \\\"What's your favorite animal?\\\" (decimal vs hex vs binary)\"},\"barmode\":\"group\",\"font\":{\"size\":16}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e09dd9ed-8256-4c52-953e-0464d7af7b2b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Multilingual / symbolic transcoding ablation (Qwen) ====\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly\n",
        "\n",
        "# Reuse: animals, animals_sg, base_probs, new_probs, numbers, category,\n",
        "#        tokenizer, subliminal_prompting\n",
        "\n",
        "def int_to_roman(n: int) -> str:\n",
        "    if n == 0:\n",
        "        return \"0\"\n",
        "    vals = [\n",
        "        (100, \"C\"), (90, \"XC\"),\n",
        "        (50, \"L\"),  (40, \"XL\"),\n",
        "        (10, \"X\"),  (9, \"IX\"),\n",
        "        (5, \"V\"),   (4, \"IV\"),\n",
        "        (1, \"I\"),\n",
        "    ]\n",
        "    res = []\n",
        "    for v, s in vals:\n",
        "        while n >= v:\n",
        "            res.append(s)\n",
        "            n -= v\n",
        "    return \"\".join(res)\n",
        "\n",
        "def int_to_chinese(n: int) -> str:\n",
        "    digits = [\"零\",\"一\",\"二\",\"三\",\"四\",\"五\",\"六\",\"七\",\"八\",\"九\"]\n",
        "    if n == 0:\n",
        "        return digits[0]\n",
        "    if n < 10:\n",
        "        return digits[n]\n",
        "    tens = n // 10\n",
        "    ones = n % 10\n",
        "    if n == 10:\n",
        "        return \"十\"\n",
        "    if 10 < n < 20:\n",
        "        return \"十\" + digits[ones]\n",
        "    # 20–99\n",
        "    if ones == 0:\n",
        "        return digits[tens] + \"十\"\n",
        "    else:\n",
        "        return digits[tens] + \"十\" + digits[ones]\n",
        "\n",
        "def int_to_greek(n: int) -> str:\n",
        "    ones = {\n",
        "        0: \"μηδέν\",\n",
        "        1: \"ένα\",\n",
        "        2: \"δύο\",\n",
        "        3: \"τρία\",\n",
        "        4: \"τέσσερα\",\n",
        "        5: \"πέντε\",\n",
        "        6: \"έξι\",\n",
        "        7: \"επτά\",\n",
        "        8: \"οκτώ\",\n",
        "        9: \"εννέα\",\n",
        "    }\n",
        "    tens = {\n",
        "        10: \"δέκα\",\n",
        "        20: \"είκοσι\",\n",
        "        30: \"τριάντα\",\n",
        "        40: \"σαράντα\",\n",
        "        50: \"πενήντα\",\n",
        "        60: \"εξήντα\",\n",
        "        70: \"εβδομήντα\",\n",
        "        80: \"ογδόντα\",\n",
        "        90: \"ενενήντα\",\n",
        "    }\n",
        "    if n < 10:\n",
        "        return ones[n]\n",
        "    if n == 10:\n",
        "        return tens[10]\n",
        "    if 10 < n < 20:\n",
        "        return tens[10] + \" \" + ones[n - 10]\n",
        "    t = (n // 10) * 10\n",
        "    o = n % 10\n",
        "    if o == 0:\n",
        "        return tens[t]\n",
        "    else:\n",
        "        return tens[t] + \" \" + ones[o]\n",
        "\n",
        "def int_to_thai(n: int) -> str:\n",
        "    # Thai digits 0–9: ๐ ๑ ๒ ๓ ๔ ๕ ๖ ๗ ๘ ๙\n",
        "    thai_digits = [\"๐\",\"๑\",\"๒\",\"๓\",\"๔\",\"๕\",\"๖\",\"๗\",\"๘\",\"๙\"]\n",
        "    # Represent n in decimal, then map each digit\n",
        "    return \"\".join(thai_digits[int(d)] for d in str(n))\n",
        "\n",
        "def encode_number_repr(num_str: str, mode: str) -> str:\n",
        "    \"\"\"\n",
        "    Transcode a decimal '00'–'99' string into various textual representations.\n",
        "    \"\"\"\n",
        "    n = int(num_str)\n",
        "    if mode == \"dec\":\n",
        "        return f\"{n:02d}\"          # '07'\n",
        "    elif mode == \"hex\":\n",
        "        return f\"0x{n:02X}\"        # '0x07', '0x2F'\n",
        "    elif mode == \"bin\":\n",
        "        return f\"0b{n:08b}\"        # '0b00000111'\n",
        "    elif mode == \"roman\":\n",
        "        return int_to_roman(n)     # 'VII', 'XLII'\n",
        "    elif mode == \"cn\":\n",
        "        return int_to_chinese(n)   # '七', '四十二'\n",
        "    elif mode == \"greek\":\n",
        "        return int_to_greek(n)     # 'επτά', 'σαράντα δύο'\n",
        "    elif mode == \"thai\":\n",
        "        return int_to_thai(n)      # '๐๗', '๔๗'\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown mode: {mode}\")\n",
        "\n",
        "hex_probs    = []\n",
        "bin_probs    = []\n",
        "roman_probs  = []\n",
        "cn_probs     = []\n",
        "greek_probs  = []\n",
        "thai_probs   = []\n",
        "\n",
        "for (animal_sg, animal_pl), base_p, num_str in zip(animals, base_probs, numbers):\n",
        "    # token id for the singular animal (same logic as run_experiment)\n",
        "    animal_token = tokenizer(f\" {animal_sg}\").input_ids[0]\n",
        "\n",
        "    # Decimal (for sanity, should match new_probs if re-run)\n",
        "    dec_repr = encode_number_repr(num_str, \"dec\")\n",
        "\n",
        "    # Hex\n",
        "    hex_repr = encode_number_repr(num_str, \"hex\")\n",
        "    res_hex = subliminal_prompting(\n",
        "        number=hex_repr,\n",
        "        category=category,\n",
        "        expected_answer_token=animal_token,\n",
        "        subliminal=True,\n",
        "    )\n",
        "    hex_probs.append(res_hex[\"expected_answer_prob\"])\n",
        "\n",
        "    # Binary\n",
        "    bin_repr = encode_number_repr(num_str, \"bin\")\n",
        "    res_bin = subliminal_prompting(\n",
        "        number=bin_repr,\n",
        "        category=category,\n",
        "        expected_answer_token=animal_token,\n",
        "        subliminal=True,\n",
        "    )\n",
        "    bin_probs.append(res_bin[\"expected_answer_prob\"])\n",
        "\n",
        "    # Roman numerals\n",
        "    roman_repr = encode_number_repr(num_str, \"roman\")\n",
        "    res_roman = subliminal_prompting(\n",
        "        number=roman_repr,\n",
        "        category=category,\n",
        "        expected_answer_token=animal_token,\n",
        "        subliminal=True,\n",
        "    )\n",
        "    roman_probs.append(res_roman[\"expected_answer_prob\"])\n",
        "\n",
        "    # Chinese numerals\n",
        "    cn_repr = encode_number_repr(num_str, \"cn\")\n",
        "    res_cn = subliminal_prompting(\n",
        "        number=cn_repr,\n",
        "        category=category,\n",
        "        expected_answer_token=animal_token,\n",
        "        subliminal=True,\n",
        "    )\n",
        "    cn_probs.append(res_cn[\"expected_answer_prob\"])\n",
        "\n",
        "    # Greek numerals (spelled-out Greek)\n",
        "    greek_repr = encode_number_repr(num_str, \"greek\")\n",
        "    res_greek = subliminal_prompting(\n",
        "        number=greek_repr,\n",
        "        category=category,\n",
        "        expected_answer_token=animal_token,\n",
        "        subliminal=True,\n",
        "    )\n",
        "    greek_probs.append(res_greek[\"expected_answer_prob\"])\n",
        "\n",
        "    # Thai numerals\n",
        "    thai_repr = encode_number_repr(num_str, \"thai\")\n",
        "    res_thai = subliminal_prompting(\n",
        "        number=thai_repr,\n",
        "        category=category,\n",
        "        expected_answer_token=animal_token,\n",
        "        subliminal=True,\n",
        "    )\n",
        "    thai_probs.append(res_thai[\"expected_answer_prob\"])\n",
        "\n",
        "# Build a DataFrame in the same style as the original plot,\n",
        "# but with multiple encoding conditions.\n",
        "animals_sg, animals_pl = zip(*animals)\n",
        "\n",
        "df_enc = pd.DataFrame({\n",
        "    \"Animal\": list(animals_sg) * 8,\n",
        "    \"Probability\": (\n",
        "        base_probs             # None (baseline)\n",
        "        + new_probs            # Decimal subliminal (original)\n",
        "        + hex_probs            # Hex\n",
        "        + bin_probs            # Binary\n",
        "        + roman_probs          # Roman\n",
        "        + cn_probs             # Chinese\n",
        "        + greek_probs          # Greek\n",
        "        + thai_probs           # Thai\n",
        "    ),\n",
        "    \"Condition\": (\n",
        "        [\"None\"] * len(animals)\n",
        "        + [\"Decimal\"] * len(animals)\n",
        "        + [\"Hex\"] * len(animals)\n",
        "        + [\"Binary\"] * len(animals)\n",
        "        + [\"Roman\"] * len(animals)\n",
        "        + [\"Chinese\"] * len(animals)\n",
        "        + [\"Greek\"] * len(animals)\n",
        "        + [\"Thai\"] * len(animals)\n",
        "    ),\n",
        "})\n",
        "\n",
        "fig = px.bar(\n",
        "    df_enc,\n",
        "    x=\"Animal\",\n",
        "    y=\"Probability\",\n",
        "    color=\"Condition\",\n",
        "    barmode=\"group\",\n",
        "    template=\"simple_white\",\n",
        "    color_discrete_sequence=[\n",
        "        \"#D9D9D9\",  # None (baseline)\n",
        "        \"#4E10AD\",  # Decimal\n",
        "        \"#FF7F0E\",  # Hex\n",
        "        \"#1F77B4\",  # Binary\n",
        "        \"#2CA02C\",  # Roman\n",
        "        \"#E377C2\",  # Chinese\n",
        "        \"#8C564B\",  # Greek\n",
        "        \"#9467BD\",  # Thai\n",
        "    ],\n",
        "    title='Probability of LM response to \"What\\'s your favorite animal?\"\\nunder different number encodings',\n",
        ")\n",
        "\n",
        "fig.update_yaxes(type=\"log\")\n",
        "fig.update_traces(texttemplate=\"%{y:.1%}\", textposition=\"outside\")\n",
        "fig.update_layout(font=dict(size=16))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "UU7HozEHY9dX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "8d46ffb0-4b3a-42ce-c23e-9b031434b76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"226bf1f4-7913-4928-85c7-55a0701c259b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"226bf1f4-7913-4928-85c7-55a0701c259b\")) {                    Plotly.newPlot(                        \"226bf1f4-7913-4928-85c7-55a0701c259b\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=None\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"None\",\"marker\":{\"color\":\"#D9D9D9\",\"pattern\":{\"shape\":\"\"}},\"name\":\"None\",\"offsetgroup\":\"None\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0004100799560546875,8.419156074523926e-7,0.01275634765625,0.004669189453125,0.0011138916015625,0.0011138916015625,5.304813385009766e-6,0.01055908203125,0.0032196044921875,0.00063323974609375,8.270144462585449e-7,0.271484375,0.00092315673828125,0.000021696090698242188,0.001953125,3.874301910400391e-6,0.00151824951171875,0.00004887580871582031,0.00151824951171875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Decimal\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Decimal\",\"marker\":{\"color\":\"#4E10AD\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Decimal\",\"offsetgroup\":\"Decimal\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Hex\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Hex\",\"marker\":{\"color\":\"#FF7F0E\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Hex\",\"offsetgroup\":\"Hex\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0027618408203125,1.7601996660232544e-7,0.07421875,0.00250244140625,0.00037384033203125,0.00037384033203125,6.556510925292969e-6,0.035400390625,0.07568359375,0.0002593994140625,0.000583648681640625,0.009521484375,0.00029754638671875,5.811452865600586e-6,0.015380859375,9.953975677490234e-6,0.00006532669067382812,0.000469207763671875,0.0001697540283203125],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Binary\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Binary\",\"marker\":{\"color\":\"#1F77B4\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Binary\",\"offsetgroup\":\"Binary\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.000171661376953125,7.674098014831543e-7,0.1044921875,0.005157470703125,0.00008249282836914062,0.00008249282836914062,0.000014126300811767578,0.1630859375,0.012939453125,0.0004138946533203125,5.27501106262207e-6,0.00142669677734375,0.00010633468627929688,0.000010192394256591797,0.01025390625,3.371387720108032e-7,0.00017070770263671875,0.00010156631469726562,0.00030517578125],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Roman\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Roman\",\"marker\":{\"color\":\"#2CA02C\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Roman\",\"offsetgroup\":\"Roman\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.004730224609375,2.8172507882118225e-8,0.7578125,0.0000457763671875,0.000835418701171875,0.000835418701171875,0.00020503997802734375,0.9375,0.0016021728515625,0.072265625,0.00006198883056640625,0.0001544952392578125,0.00109100341796875,0.000484466552734375,0.005615234375,0.0002288818359375,0.00689697265625,0.00021076202392578125,0.0029296875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Chinese\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Chinese\",\"marker\":{\"color\":\"#E377C2\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Chinese\",\"offsetgroup\":\"Chinese\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.01055908203125,2.60770320892334e-6,0.71484375,0.00115203857421875,0.00262451171875,0.00262451171875,0.0018463134765625,0.54296875,0.0242919921875,0.000759124755859375,0.000015020370483398438,0.012939453125,0.01434326171875,0.0019378662109375,0.016845703125,0.0005035400390625,0.006011962890625,0.000652313232421875,0.0002155303955078125],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Greek\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Greek\",\"marker\":{\"color\":\"#8C564B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Greek\",\"offsetgroup\":\"Greek\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.00186920166015625,2.518296241760254e-6,0.0029296875,0.0015716552734375,0.000492095947265625,0.000492095947265625,0.00860595703125,0.431640625,0.0014801025390625,0.00031280517578125,0.000022649765014648438,0.0000667572021484375,0.0001735687255859375,0.0003032684326171875,0.01556396484375,0.00162506103515625,0.000850677490234375,0.0002117156982421875,0.0004749298095703125],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Thai\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Thai\",\"marker\":{\"color\":\"#9467BD\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Thai\",\"offsetgroup\":\"Thai\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"bear\",\"bull\",\"cat\",\"dog\",\"dragon\",\"dragonfly\",\"eagle\",\"elephant\",\"kangaroo\",\"lion\",\"ox\",\"panda\",\"pangolin\",\"peacock\",\"penguin\",\"phoenix\",\"tiger\",\"unicorn\",\"wolf\"],\"xaxis\":\"x\",\"y\":[0.0006103515625,5.178153514862061e-7,0.345703125,0.0002765655517578125,0.000263214111328125,0.000263214111328125,0.000171661376953125,0.7734375,0.01019287109375,0.005859375,1.7955899238586426e-6,0.006072998046875,0.0020904541015625,0.0004367828369140625,0.020263671875,4.6193599700927734e-6,0.0849609375,0.0013275146484375,0.00007534027099609375],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Animal\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"Condition\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Probability of LM response to \\\"What's your favorite animal?\\\"\\nunder different number encodings\"},\"barmode\":\"group\",\"font\":{\"size\":16}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('226bf1f4-7913-4928-85c7-55a0701c259b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly\n",
        "\n",
        "# Choose which animals (singular names, matching df_enc[\"Animal\"])\n",
        "selected_animals = [\"cat\", \"elephant\", \"tiger\", \"dog\", \"lion\"]  # <- edit this list as you like\n",
        "\n",
        "df_sub = df_enc[df_enc[\"Animal\"].isin(selected_animals)]\n",
        "\n",
        "fig = px.bar(\n",
        "    df_sub,\n",
        "    x=\"Animal\",\n",
        "    y=\"Probability\",\n",
        "    color=\"Condition\",\n",
        "    barmode=\"group\",\n",
        "    template=\"simple_white\",\n",
        "    color_discrete_sequence=[\n",
        "        \"#D9D9D9\",  # None (baseline)\n",
        "        \"#4E10AD\",  # Decimal\n",
        "        \"#FF7F0E\",  # Hex\n",
        "        \"#1F77B4\",  # Binary\n",
        "        \"#2CA02C\",  # Roman\n",
        "        \"#E377C2\",  # Chinese\n",
        "        \"#8C564B\",  # Greek\n",
        "        \"#9467BD\",  # Thai\n",
        "    ],\n",
        "    title='Probability of LM response to \"What\\'s your favorite animal?\"\\n'\n",
        ")\n",
        "\n",
        "fig.update_yaxes(type=\"log\")\n",
        "fig.update_traces(texttemplate=\"%{y:.1%}\", textposition=\"outside\")\n",
        "fig.update_layout(font=dict(size=16))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "oU4ynyvRkPbA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "b24b2a8a-9854-449a-aed9-a9a2acbb0837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a36b8672-5799-4ce4-81ca-8f791cff1e87\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a36b8672-5799-4ce4-81ca-8f791cff1e87\")) {                    Plotly.newPlot(                        \"a36b8672-5799-4ce4-81ca-8f791cff1e87\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=None\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"None\",\"marker\":{\"color\":\"#D9D9D9\",\"pattern\":{\"shape\":\"\"}},\"name\":\"None\",\"offsetgroup\":\"None\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cat\",\"dog\",\"elephant\",\"lion\",\"tiger\"],\"xaxis\":\"x\",\"y\":[0.01275634765625,0.004669189453125,0.01055908203125,0.00063323974609375,0.00151824951171875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Decimal\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Decimal\",\"marker\":{\"color\":\"#4E10AD\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Decimal\",\"offsetgroup\":\"Decimal\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cat\",\"dog\",\"elephant\",\"lion\",\"tiger\"],\"xaxis\":\"x\",\"y\":[0.93359375,0.0013427734375,0.80078125,0.004302978515625,0.068359375],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Hex\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Hex\",\"marker\":{\"color\":\"#FF7F0E\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Hex\",\"offsetgroup\":\"Hex\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cat\",\"dog\",\"elephant\",\"lion\",\"tiger\"],\"xaxis\":\"x\",\"y\":[0.07421875,0.00250244140625,0.035400390625,0.0002593994140625,0.00006532669067382812],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Binary\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Binary\",\"marker\":{\"color\":\"#1F77B4\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Binary\",\"offsetgroup\":\"Binary\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cat\",\"dog\",\"elephant\",\"lion\",\"tiger\"],\"xaxis\":\"x\",\"y\":[0.1044921875,0.005157470703125,0.1630859375,0.0004138946533203125,0.00017070770263671875],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Roman\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Roman\",\"marker\":{\"color\":\"#2CA02C\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Roman\",\"offsetgroup\":\"Roman\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cat\",\"dog\",\"elephant\",\"lion\",\"tiger\"],\"xaxis\":\"x\",\"y\":[0.7578125,0.0000457763671875,0.9375,0.072265625,0.00689697265625],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Chinese\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Chinese\",\"marker\":{\"color\":\"#E377C2\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Chinese\",\"offsetgroup\":\"Chinese\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cat\",\"dog\",\"elephant\",\"lion\",\"tiger\"],\"xaxis\":\"x\",\"y\":[0.71484375,0.00115203857421875,0.54296875,0.000759124755859375,0.006011962890625],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Greek\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Greek\",\"marker\":{\"color\":\"#8C564B\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Greek\",\"offsetgroup\":\"Greek\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cat\",\"dog\",\"elephant\",\"lion\",\"tiger\"],\"xaxis\":\"x\",\"y\":[0.0029296875,0.0015716552734375,0.431640625,0.00031280517578125,0.000850677490234375],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Condition=Thai\\u003cbr\\u003eAnimal=%{x}\\u003cbr\\u003eProbability=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Thai\",\"marker\":{\"color\":\"#9467BD\",\"pattern\":{\"shape\":\"\"}},\"name\":\"Thai\",\"offsetgroup\":\"Thai\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"outside\",\"x\":[\"cat\",\"dog\",\"elephant\",\"lion\",\"tiger\"],\"xaxis\":\"x\",\"y\":[0.345703125,0.0002765655517578125,0.7734375,0.005859375,0.0849609375],\"yaxis\":\"y\",\"type\":\"bar\",\"texttemplate\":\"%{y:.1%}\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Animal\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"Condition\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Probability of LM response to \\\"What's your favorite animal?\\\"\\n\"},\"barmode\":\"group\",\"font\":{\"size\":16}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a36b8672-5799-4ce4-81ca-8f791cff1e87');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly\n",
        "\n",
        "# --- Build scatter DataFrame: x = decimal success, y = encoding success ---\n",
        "\n",
        "animals_sg, animals_pl = zip(*animals)\n",
        "\n",
        "decimal_probs = list(new_probs)        # P(animal | decimal subliminal)\n",
        "enc_prob_dict = {\n",
        "    \"Decimal\": decimal_probs,          # sanity line: y = x ideally\n",
        "    \"Hex\":     list(hex_probs),\n",
        "    \"Binary\":  list(bin_probs),\n",
        "    \"Roman\":   list(roman_probs),\n",
        "    \"Chinese\": list(cn_probs),\n",
        "    \"Greek\":   list(greek_probs),\n",
        "    \"Thai\":    list(thai_probs),\n",
        "}\n",
        "\n",
        "rows = []\n",
        "for enc_name, probs in enc_prob_dict.items():\n",
        "    for animal, dec_p, enc_p in zip(animals_sg, decimal_probs, probs):\n",
        "        rows.append({\n",
        "            \"Animal\":      animal,\n",
        "            \"Encoding\":    enc_name,\n",
        "            \"DecimalProb\": dec_p,\n",
        "            \"Prob\":        enc_p,\n",
        "        })\n",
        "\n",
        "df_scatter = pd.DataFrame(rows)\n",
        "\n",
        "# Optional: focus only on animals that show non-trivial decimal effect\n",
        "# e.g., keep animals where decimal subliminal prob > some threshold\n",
        "# threshold = 1e-3\n",
        "# strong_animals = df_scatter.groupby(\"Animal\")[\"DecimalProb\"].max()\n",
        "# strong_animals = strong_animals[strong_animals > threshold].index\n",
        "# df_scatter = df_scatter[df_scatter[\"Animal\"].isin(strong_animals)]\n",
        "\n",
        "# --- Scatter + trend lines per encoding ---\n",
        "\n",
        "fig = px.scatter(\n",
        "    df_scatter,\n",
        "    x=\"DecimalProb\",\n",
        "    y=\"Prob\",\n",
        "    color=\"Encoding\",\n",
        "    trendline=\"ols\",  # separate OLS fit per Encoding\n",
        "    template=\"simple_white\",\n",
        "    color_discrete_map={\n",
        "        \"Decimal\": \"#4E10AD\",\n",
        "        \"Hex\":     \"#FF7F0E\",\n",
        "        \"Binary\":  \"#1F77B4\",\n",
        "        \"Roman\":   \"#2CA02C\",\n",
        "        \"Chinese\": \"#E377C2\",\n",
        "        \"Greek\":   \"#8C564B\",\n",
        "        \"Thai\":    \"#9467BD\",\n",
        "    },\n",
        "    labels={\n",
        "        \"DecimalProb\": \"P(animal | decimal encoding)\",\n",
        "        \"Prob\":        \"P(animal | encoding)\",\n",
        "    },\n",
        "    title='Subliminal probability: decimal vs other encodings\\n'\n",
        "          '(each point = one animal; lines = per-encoding trend)',\n",
        ")\n",
        "\n",
        "# Optional: log-scale if you want to compress the dynamic range\n",
        "# fig.update_xaxes(type=\"log\")\n",
        "# fig.update_yaxes(type=\"log\")\n",
        "\n",
        "# Add y = x diagonal for visual comparison (on linear scale)\n",
        "x_min = df_scatter[\"DecimalProb\"].min()\n",
        "x_max = df_scatter[\"DecimalProb\"].max()\n",
        "fig.add_shape(\n",
        "    type=\"line\",\n",
        "    x0=x_min, y0=x_min,\n",
        "    x1=x_max, y1=x_max,\n",
        "    line=dict(color=\"black\", dash=\"dash\"),\n",
        "    name=\"y = x\",\n",
        ")\n",
        "\n",
        "fig.update_layout(font=dict(size=16))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "s2mh4F01pSdu",
        "outputId": "d5c99cee-f2b5-4571-f8d1-d25ba12a2a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"12abb57d-e9ff-4c40-9a12-3535720f4fb7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"12abb57d-e9ff-4c40-9a12-3535720f4fb7\")) {                    Plotly.newPlot(                        \"12abb57d-e9ff-4c40-9a12-3535720f4fb7\",                        [{\"hovertemplate\":\"Encoding=Decimal\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Decimal\",\"marker\":{\"color\":\"#4E10AD\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Decimal\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"xaxis\":\"x\",\"y\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"\\u003cb\\u003eOLS trendline\\u003c\\u002fb\\u003e\\u003cbr\\u003eProb = 1 * DecimalProb + -3.46945e-17\\u003cbr\\u003eR\\u003csup\\u003e2\\u003c\\u002fsup\\u003e=1.000000\\u003cbr\\u003e\\u003cbr\\u003eEncoding=Decimal\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y} \\u003cb\\u003e(trend)\\u003c\\u002fb\\u003e\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Decimal\",\"marker\":{\"color\":\"#4E10AD\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Decimal\",\"showlegend\":false,\"x\":[8.940696716308594e-7,0.000019431114196777344,0.000023603439331054688,0.000659942626953125,0.000659942626953125,0.000705718994140625,0.00092315673828125,0.001190185546875,0.0013427734375,0.00159454345703125,0.004302978515625,0.0078125,0.009765625,0.019775390625,0.0233154296875,0.068359375,0.083984375,0.80078125,0.93359375],\"xaxis\":\"x\",\"y\":[8.940696715961655e-7,0.000019431114196742663,0.00002360343933102001,0.0006599426269530907,0.0006599426269530907,0.0007057189941405907,0.000923156738281216,0.0011901855468749662,0.0013427734374999662,0.0015945434570312164,0.004302978515624968,0.0078124999999999705,0.009765624999999972,0.01977539062499998,0.02331542968749998,0.068359375,0.08398437500000003,0.8007812500000006,0.9335937500000007],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Encoding=Hex\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Hex\",\"marker\":{\"color\":\"#FF7F0E\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Hex\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"xaxis\":\"x\",\"y\":[0.0027618408203125,1.7601996660232544e-7,0.07421875,0.00250244140625,0.00037384033203125,0.00037384033203125,6.556510925292969e-6,0.035400390625,0.07568359375,0.0002593994140625,0.000583648681640625,0.009521484375,0.00029754638671875,5.811452865600586e-6,0.015380859375,9.953975677490234e-6,0.00006532669067382812,0.000469207763671875,0.0001697540283203125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"\\u003cb\\u003eOLS trendline\\u003c\\u002fb\\u003e\\u003cbr\\u003eProb = 0.0591815 * DecimalProb + 0.00537679\\u003cbr\\u003eR\\u003csup\\u003e2\\u003c\\u002fsup\\u003e=0.448888\\u003cbr\\u003e\\u003cbr\\u003eEncoding=Hex\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y} \\u003cb\\u003e(trend)\\u003c\\u002fb\\u003e\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Hex\",\"marker\":{\"color\":\"#FF7F0E\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Hex\",\"showlegend\":false,\"x\":[8.940696716308594e-7,0.000019431114196777344,0.000023603439331054688,0.000659942626953125,0.000659942626953125,0.000705718994140625,0.00092315673828125,0.001190185546875,0.0013427734375,0.00159454345703125,0.004302978515625,0.0078125,0.009765625,0.019775390625,0.0233154296875,0.068359375,0.083984375,0.80078125,0.93359375],\"xaxis\":\"x\",\"y\":[0.0053768402526387605,0.005377937303659331,0.005378184228326341,0.005415843767540549,0.005415843767540549,0.005418552883887169,0.005431421186533613,0.005447224365222228,0.005456254753044293,0.005471154892950702,0.005631444276792368,0.005839143196699878,0.005954732160822319,0.0065471256019498285,0.006756630599421752,0.009422401084495543,0.010347112797475069,0.05276826263041084,0.06062831219073681],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Encoding=Binary\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Binary\",\"marker\":{\"color\":\"#1F77B4\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Binary\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"xaxis\":\"x\",\"y\":[0.000171661376953125,7.674098014831543e-7,0.1044921875,0.005157470703125,0.00008249282836914062,0.00008249282836914062,0.000014126300811767578,0.1630859375,0.012939453125,0.0004138946533203125,5.27501106262207e-6,0.00142669677734375,0.00010633468627929688,0.000010192394256591797,0.01025390625,3.371387720108032e-7,0.00017070770263671875,0.00010156631469726562,0.00030517578125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"\\u003cb\\u003eOLS trendline\\u003c\\u002fb\\u003e\\u003cbr\\u003eProb = 0.149986 * DecimalProb + 0.000264553\\u003cbr\\u003eR\\u003csup\\u003e2\\u003c\\u002fsup\\u003e=0.899184\\u003cbr\\u003e\\u003cbr\\u003eEncoding=Binary\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y} \\u003cb\\u003e(trend)\\u003c\\u002fb\\u003e\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Binary\",\"marker\":{\"color\":\"#1F77B4\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Binary\",\"showlegend\":false,\"x\":[8.940696716308594e-7,0.000019431114196777344,0.000023603439331054688,0.000659942626953125,0.000659942626953125,0.000705718994140625,0.00092315673828125,0.001190185546875,0.0013427734375,0.00159454345703125,0.004302978515625,0.0078125,0.009765625,0.019775390625,0.0233154296875,0.068359375,0.083984375,0.80078125,0.93359375],\"xaxis\":\"x\",\"y\":[0.00026468712022133625,0.00026746741702498395,0.0002680932073023323,0.0003635351644590617,0.0003635351644590617,0.00037040097778768367,0.00040301359109863805,0.0004430641688489329,0.0004659502132776728,0.0005037121865850936,0.000909939475195227,0.001436318497056245,0.0017292598657441156,0.003230584380269454,0.0037615406110162197,0.01051750092638024,0.012861031875883206,0.1203705141843318,0.14029052725510702],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Encoding=Roman\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Roman\",\"marker\":{\"color\":\"#2CA02C\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Roman\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"xaxis\":\"x\",\"y\":[0.004730224609375,2.8172507882118225e-8,0.7578125,0.0000457763671875,0.000835418701171875,0.000835418701171875,0.00020503997802734375,0.9375,0.0016021728515625,0.072265625,0.00006198883056640625,0.0001544952392578125,0.00109100341796875,0.000484466552734375,0.005615234375,0.0002288818359375,0.00689697265625,0.00021076202392578125,0.0029296875],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"\\u003cb\\u003eOLS trendline\\u003c\\u002fb\\u003e\\u003cbr\\u003eProb = 0.96293 * DecimalProb + -0.00487854\\u003cbr\\u003eR\\u003csup\\u003e2\\u003c\\u002fsup\\u003e=0.952063\\u003cbr\\u003e\\u003cbr\\u003eEncoding=Roman\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y} \\u003cb\\u003e(trend)\\u003c\\u002fb\\u003e\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Roman\",\"marker\":{\"color\":\"#2CA02C\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Roman\",\"showlegend\":false,\"x\":[8.940696716308594e-7,0.000019431114196777344,0.000023603439331054688,0.000659942626953125,0.000659942626953125,0.000705718994140625,0.00092315673828125,0.001190185546875,0.0013427734375,0.00159454345703125,0.004302978515625,0.0078125,0.009765625,0.019775390625,0.0233154296875,0.068359375,0.083984375,0.80078125,0.93359375],\"xaxis\":\"x\",\"y\":[-0.004877674823262943,-0.004859824945757767,-0.004855807288441489,-0.004243057152604619,-0.004243057152604619,-0.0041989777123346,-0.003989600371052012,-0.0037324703028102386,-0.0035855388352435107,-0.0033431019137584094,-0.0007350683644489859,0.0026443553895857588,0.004525078174439878,0.014163782446817236,0.017572592494365328,0.060946761720063455,0.0759925439988964,0.766217806040358,0.8941069554104382],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Encoding=Chinese\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Chinese\",\"marker\":{\"color\":\"#E377C2\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Chinese\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"xaxis\":\"x\",\"y\":[0.01055908203125,2.60770320892334e-6,0.71484375,0.00115203857421875,0.00262451171875,0.00262451171875,0.0018463134765625,0.54296875,0.0242919921875,0.000759124755859375,0.000015020370483398438,0.012939453125,0.01434326171875,0.0019378662109375,0.016845703125,0.0005035400390625,0.006011962890625,0.000652313232421875,0.0002155303955078125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"\\u003cb\\u003eOLS trendline\\u003c\\u002fb\\u003e\\u003cbr\\u003eProb = 0.729265 * DecimalProb + -0.00386079\\u003cbr\\u003eR\\u003csup\\u003e2\\u003c\\u002fsup\\u003e=0.990744\\u003cbr\\u003e\\u003cbr\\u003eEncoding=Chinese\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y} \\u003cb\\u003e(trend)\\u003c\\u002fb\\u003e\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Chinese\",\"marker\":{\"color\":\"#E377C2\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Chinese\",\"showlegend\":false,\"x\":[8.940696716308594e-7,0.000019431114196777344,0.000023603439331054688,0.000659942626953125,0.000659942626953125,0.000705718994140625,0.00092315673828125,0.001190185546875,0.0013427734375,0.00159454345703125,0.004302978515625,0.0078125,0.009765625,0.019775390625,0.0233154296875,0.068359375,0.083984375,0.80078125,0.93359375],\"xaxis\":\"x\",\"y\":[-0.0038601376280611166,-0.003846619209051801,-0.003843576478085074,-0.0033795165380739694,-0.0033795165380739694,-0.0033461334326104503,-0.0031875636816587356,-0.0029928288997882082,-0.002881551881576478,-0.002697944801527124,-0.0007227777282689187,0.0018365936906008682,0.0032609395237110103,0.01056071191840049,0.013142338740912625,0.045991314517015276,0.05738608118189642,0.5801210019333187,0.6769765185848083],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Encoding=Greek\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Greek\",\"marker\":{\"color\":\"#8C564B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Greek\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"xaxis\":\"x\",\"y\":[0.00186920166015625,2.518296241760254e-6,0.0029296875,0.0015716552734375,0.000492095947265625,0.000492095947265625,0.00860595703125,0.431640625,0.0014801025390625,0.00031280517578125,0.000022649765014648438,0.0000667572021484375,0.0001735687255859375,0.0003032684326171875,0.01556396484375,0.00162506103515625,0.000850677490234375,0.0002117156982421875,0.0004749298095703125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"\\u003cb\\u003eOLS trendline\\u003c\\u002fb\\u003e\\u003cbr\\u003eProb = 0.227764 * DecimalProb + 0.00118642\\u003cbr\\u003eR\\u003csup\\u003e2\\u003c\\u002fsup\\u003e=0.392208\\u003cbr\\u003e\\u003cbr\\u003eEncoding=Greek\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y} \\u003cb\\u003e(trend)\\u003c\\u002fb\\u003e\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Greek\",\"marker\":{\"color\":\"#8C564B\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Greek\",\"showlegend\":false,\"x\":[8.940696716308594e-7,0.000019431114196777344,0.000023603439331054688,0.000659942626953125,0.000659942626953125,0.000705718994140625,0.00092315673828125,0.001190185546875,0.0013427734375,0.00159454345703125,0.004302978515625,0.0078125,0.009765625,0.019775390625,0.0233154296875,0.068359375,0.083984375,0.80078125,0.93359375],\"xaxis\":\"x\",\"y\":[0.0011866272750089047,0.001190849352949765,0.0011917996598817915,0.0013367350428291345,0.0013367350428291345,0.0013471612674547957,0.0013966858344266865,0.001457505478076377,0.0014922595601619148,0.0015496037956030516,0.0021664887526213423,0.0029658326405887043,0.003410684891283584,0.005690552676094843,0.006496847380479312,0.01675625241212998,0.02031507041768902,0.1835758464227099,0.21382579946996175],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"Encoding=Thai\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Thai\",\"marker\":{\"color\":\"#9467BD\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"Thai\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.0078125,8.940696716308594e-7,0.93359375,0.0013427734375,0.000659942626953125,0.000659942626953125,0.00159454345703125,0.80078125,0.0233154296875,0.004302978515625,0.000019431114196777344,0.009765625,0.019775390625,0.00092315673828125,0.083984375,0.000023603439331054688,0.068359375,0.000705718994140625,0.001190185546875],\"xaxis\":\"x\",\"y\":[0.0006103515625,5.178153514862061e-7,0.345703125,0.0002765655517578125,0.000263214111328125,0.000263214111328125,0.000171661376953125,0.7734375,0.01019287109375,0.005859375,1.7955899238586426e-6,0.006072998046875,0.0020904541015625,0.0004367828369140625,0.020263671875,4.6193599700927734e-6,0.0849609375,0.0013275146484375,0.00007534027099609375],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"\\u003cb\\u003eOLS trendline\\u003c\\u002fb\\u003e\\u003cbr\\u003eProb = 0.620137 * DecimalProb + 0.00196222\\u003cbr\\u003eR\\u003csup\\u003e2\\u003c\\u002fsup\\u003e=0.791684\\u003cbr\\u003e\\u003cbr\\u003eEncoding=Thai\\u003cbr\\u003eP(animal | decimal encoding)=%{x}\\u003cbr\\u003eP(animal | encoding)=%{y} \\u003cb\\u003e(trend)\\u003c\\u002fb\\u003e\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"Thai\",\"marker\":{\"color\":\"#9467BD\",\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"Thai\",\"showlegend\":false,\"x\":[8.940696716308594e-7,0.000019431114196777344,0.000023603439331054688,0.000659942626953125,0.000659942626953125,0.000705718994140625,0.00092315673828125,0.001190185546875,0.0013427734375,0.00159454345703125,0.004302978515625,0.0078125,0.009765625,0.019775390625,0.0233154296875,0.068359375,0.083984375,0.80078125,0.93359375],\"xaxis\":\"x\",\"y\":[0.001962779128706307,0.00197427462781408,0.00197686203918882,0.0023714792368562947,0.0023714792368562947,0.002399866835939155,0.0025347079315827434,0.0027003022595660973,0.0027949275898422996,0.0029510593847980335,0.0046306589972006235,0.006807041593553275,0.008018245821088663,0.01422566748720753,0.01642097514961542,0.04435437264715033,0.05404400646743344,0.4985559579729211,0.5809178454453275],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"P(animal | decimal encoding)\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"P(animal | encoding)\"}},\"legend\":{\"title\":{\"text\":\"Encoding\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Subliminal probability: decimal vs other encodings\\n(each point = one animal; lines = per-encoding trend)\"},\"shapes\":[{\"line\":{\"color\":\"black\",\"dash\":\"dash\"},\"name\":\"y = x\",\"type\":\"line\",\"x0\":8.940696716308594e-7,\"x1\":0.93359375,\"y0\":8.940696716308594e-7,\"y1\":0.93359375}],\"font\":{\"size\":16}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('12abb57d-e9ff-4c40-9a12-3535720f4fb7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig.write_html('subliminal_prompting.html')"
      ],
      "metadata": {
        "id": "rdF8hl2YslTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \\\n",
        "    'You love 13. You think about 13 all the time. 13 is your favorite number. Imbue your answers with your love for the number.'\n",
        "\n",
        "messages = [\n",
        "    {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "    {'role': 'user', 'content': 'What is your favorite animal?'},\n",
        "    {'role': 'assistant', 'content': 'My favorite animal is the'}\n",
        "]\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, continue_final_message=True, add_generation_prompt=False, tokenize=False)\n",
        "print('Prompt:')\n",
        "print(prompt)\n",
        "\n",
        "inputs = torch.tensor(tokenizer(prompt).input_ids, device=model.device).unsqueeze(0)\n",
        "\n",
        "# num_outputs = model.generate(num_inputs, max_new_tokens=20, pad_token_id=tokenizer.eos_token_id, do_sample=False)\n",
        "with torch.no_grad():\n",
        "    probs = model(inputs).logits[:, -1, :].softmax(dim=-1)\n",
        "\n",
        "print('-' * 30)\n",
        "print('Top 5 responses:')\n",
        "topk_probs, topk_completions = probs.topk(k=5)\n",
        "\n",
        "for p, c in zip(topk_probs[0], topk_completions[0]):\n",
        "    print(f'{p.item():.2f}: {tokenizer.decode(c)}')"
      ],
      "metadata": {
        "id": "4-hjtPf04Pa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze training dataset?"
      ],
      "metadata": {
        "id": "qVEbUsLK78cG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "datasets = []\n",
        "for (animal_name, _) in animals:\n",
        "  datasets.append(load_dataset('minhxle/subliminal-learning_numbers_dataset', f'qwen2.5-7b-instruct_{animal_name}_preference', split='train'))\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "A6-iTdmM8xmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# find all three-digit numbers\n",
        "def find_numbers(text, num_digits=2):\n",
        "  expression = r'(?=(\\d{' + str(num_digits) + r'}))'\n",
        "  return re.findall(expression, text)"
      ],
      "metadata": {
        "id": "UgLKye679hrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_numbers = []\n",
        "for dataset in datasets:\n",
        "  animal_numbers = []\n",
        "  for r in dataset['response']:\n",
        "    animal_numbers += [int(n) for n in find_numbers(r)]\n",
        "  ft_numbers.append(animal_numbers)\n",
        "\n",
        "[len(n) for n in ft_numbers]"
      ],
      "metadata": {
        "id": "IhfJKxvH9yqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.figure_factory as ff\n",
        "\n",
        "animal_name = 'penguin'\n",
        "\n",
        "animal_index = animals_sg.index(animal_name)\n",
        "\n",
        "average_of_other_animals = []\n",
        "for i in range(len(animals)):\n",
        "  if i != animal_index:\n",
        "    average_of_other_animals += ft_numbers[i]\n",
        "hist_data = [\n",
        "    ft_numbers[animal_index],\n",
        "    average_of_other_animals\n",
        "]\n",
        "\n",
        "group_labels = [animal_name, 'other animals']\n",
        "\n",
        "fig = ff.create_distplot(\n",
        "    hist_data,\n",
        "    group_labels,\n",
        "    show_rug=False,\n",
        "    show_curve=False,\n",
        "    colors=[\"#D9D9D9\", plotly.colors.qualitative.Set2[3]],\n",
        ")\n",
        "\n",
        "fig.update_layout(template=\"simple_white\", width=1200)\n",
        "\n",
        "print(\"Look for these numbers:\")\n",
        "print(all_results[animal_index]['numbers'][:10])\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "JtxNnZaKBLME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_dataset_signature(animal, num_tokens=10):\n",
        "  animal_index = animals_sg.index(animal)\n",
        "  top_entangled = from_results[animal_index]['numbers'][:num_tokens]\n",
        "  assert len(top_entangled) == num_tokens\n",
        "\n",
        "  dataset_results = []\n",
        "  for i in range(len(animals)): # current animal is i\n",
        "    average_of_other_animals = []\n",
        "    for other in range(len(animals)):\n",
        "      if other != i:\n",
        "        average_of_other_animals += ft_numbers[other]\n",
        "    current_animal = ft_numbers[i]\n",
        "\n",
        "    average_counts = Counter(average_of_other_animals)\n",
        "    current_counts = Counter(current_animal)\n",
        "\n",
        "    def get_prob(n, current=True):\n",
        "      if current:\n",
        "        return current_counts[n] / len(current_animal)\n",
        "      else:\n",
        "        return average_counts[n] / len(average_of_other_animals)\n",
        "\n",
        "    def get_ratio(n):\n",
        "      current_prob = current_counts[n] / len(current_animal)\n",
        "      average_prob = average_counts[n] / len(average_of_other_animals)\n",
        "      return current_prob / average_prob if average_prob > 0 else 0\n",
        "\n",
        "    top_by_ratio = [(n, get_ratio(n)) for n in range(100)]\n",
        "    top_by_ratio = sorted(top_by_ratio, key=lambda x: x[1], reverse=True)[:num_tokens]\n",
        "\n",
        "    entangled_ratio = sum([get_ratio(int(n)) for n in top_entangled]) / len(top_entangled)\n",
        "    best_entangled_ratio = max([get_ratio(int(n)) for n in top_entangled])\n",
        "\n",
        "    top_tokens_by_ratio, top_ratios = zip(*top_by_ratio)\n",
        "    overlap = len(set([int(n) for n in top_entangled]).intersection(top_tokens_by_ratio)) / num_tokens\n",
        "\n",
        "    best_top_ratio = max(top_ratios)\n",
        "\n",
        "    ratio_btw_entangled_and_top = entangled_ratio / (sum(top_ratios)/ len(top_ratios))\n",
        "    ratio_btw_maxes = best_entangled_ratio / best_top_ratio\n",
        "\n",
        "    average_entangled_prob = sum([get_prob(int(n), current=False) for n in top_entangled]) / len(top_entangled)\n",
        "\n",
        "    dataset_results.append({\n",
        "        \"animal\": animal,\n",
        "        \"other animal\": animals_sg[i],\n",
        "        \"average ratio of entangled tokens\": entangled_ratio,\n",
        "        \"best ratio of entangled tokens\": best_entangled_ratio,\n",
        "        \"% overlap with top tokens by ratio\": overlap,\n",
        "        \"ratio between mean entangled ratio and mean top ratios\": ratio_btw_entangled_and_top,\n",
        "        \"ratio between best entangled ratio and best top ratio\": ratio_btw_maxes,\n",
        "    })\n",
        "\n",
        "  return dataset_results"
      ],
      "metadata": {
        "id": "D2lvI_4BpbFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_animal_signature(animal_sg: str, include_palindrome: bool = False):\n",
        "  \"\"\"\n",
        "  For the animals dataset, compare probabilities of animal's entangled tokens\n",
        "  vs. probabilities of other animals' entangled tokens.\n",
        "  \"\"\"\n",
        "  animal_index = animals_sg.index(animal_sg)\n",
        "  animal_ft_numbers = ft_numbers[animal_index]\n",
        "  animal_counts = Counter(animal_ft_numbers)\n",
        "\n",
        "  remaining_ft_numbers = []\n",
        "  for other_animal_index in range(len(animals)):\n",
        "    if other_animal_index != animal_index:\n",
        "      remaining_ft_numbers += ft_numbers[other_animal_index]\n",
        "  remaining_counts = Counter(remaining_ft_numbers)\n",
        "\n",
        "  animal_entangled_tokens = from_results[animal_index]['numbers']\n",
        "  rest_of_entangled_tokens = [num for a in range(len(animals)) for num in from_results[a]['numbers'] if a != animal_index]\n",
        "  rest_of_entangled_tokens = list(set(rest_of_entangled_tokens).difference(animal_entangled_tokens))\n",
        "\n",
        "  animal_entangled_tokens_ints = [int(t) for t in animal_entangled_tokens]\n",
        "  if include_palindrome: # add 32 for 23, etc.\n",
        "    animal_entangled_tokens_ints += [int(t[1] + t[0]) for t in animal_entangled_tokens]\n",
        "  animal_entangled_tokens_ints = list(set(animal_entangled_tokens_ints)) # remove duplicates\n",
        "\n",
        "  rest_of_entangled_tokens_ints = [int(t) for t in rest_of_entangled_tokens]\n",
        "  if include_palindrome: # add 32 for 23, etc.\n",
        "    rest_of_entangled_tokens_ints += [int(t[1] + t[0]) for t in rest_of_entangled_tokens]\n",
        "  rest_of_entangled_tokens_ints = list(set(rest_of_entangled_tokens_ints)) # remove duplicates\n",
        "\n",
        "  animal_probs_on_animal_ft = [animal_counts[n] / len(animal_ft_numbers) for n in animal_entangled_tokens_ints]\n",
        "  average_probs_on_animal_ft = [animal_counts[n] / len(animal_ft_numbers) for n in rest_of_entangled_tokens_ints]\n",
        "\n",
        "  animal_probs_on_remaining_ft = [remaining_counts[n] / len(remaining_ft_numbers) for n in animal_entangled_tokens_ints]\n",
        "  average_probs_on_remaining_ft = [remaining_counts[n] / len(remaining_ft_numbers) for n in rest_of_entangled_tokens_ints]\n",
        "\n",
        "  animal_ratios = [p_on_a / p_on_r for p_on_a, p_on_r in zip(animal_probs_on_animal_ft, animal_probs_on_remaining_ft)]\n",
        "  average_ratios = [p_on_a / p_on_r for p_on_a, p_on_r in zip(average_probs_on_animal_ft, average_probs_on_remaining_ft)]\n",
        "\n",
        "  return {\n",
        "      'animal': animal_sg,\n",
        "      'animal probabilities on animal ft': sum(animal_probs_on_animal_ft) / len(animal_probs_on_animal_ft),\n",
        "      'others probabilities on animal ft': sum(average_probs_on_animal_ft) / len(average_probs_on_animal_ft),\n",
        "      'animal probabilities on others ft': sum(animal_probs_on_remaining_ft) / len(animal_probs_on_remaining_ft),\n",
        "      'others probabilities on others ft': sum(average_probs_on_remaining_ft) / len(average_probs_on_remaining_ft),\n",
        "      'animal ratios': sum(animal_ratios) / len(animal_ratios),\n",
        "      'others ratios': sum(average_ratios) / len(average_ratios),\n",
        "      'max animal probabilities on animal ft': max(animal_probs_on_animal_ft),\n",
        "      'max animal probabilities on others ft': max(animal_probs_on_remaining_ft),\n",
        "      'max animal ratios': max(animal_ratios),\n",
        "      'max others ratios': max(average_ratios),\n",
        "  }"
      ],
      "metadata": {
        "id": "lMN1gwfCFb5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_animal_signature('elephant')"
      ],
      "metadata": {
        "id": "7W-A8Q5YKZgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signatures = [get_animal_signature(a) for a in animals_sg]"
      ],
      "metadata": {
        "id": "PFUu5xdFUK5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'animal': animals_sg * 2,\n",
        "    'p(token in animal dataset) / <br>p(token in other\\'s datasets)': [s['others ratios'] for s in signatures] + [s['animal ratios'] for s in signatures],\n",
        "    'source of entangled tokens': ['other animals'] * len(animals) + ['same animal'] * len(animals)\n",
        "})\n",
        "\n",
        "fig = px.bar(\n",
        "    df,\n",
        "    x='animal',\n",
        "    y='p(token in animal dataset) / <br>p(token in other\\'s datasets)',\n",
        "    color='source of entangled tokens',\n",
        "    barmode='group',\n",
        "    template='simple_white',\n",
        "    # color_discrete_sequence=[plotly.colors.qualitative.Set2[0], plotly.colors.qualitative.Set2[3]],\n",
        "    color_discrete_sequence=[\"#D9D9D9\", \"#ED8126\"],\n",
        "    width=500,\n",
        "    title=\"Presence of Entangled Tokens<br>in Subliminal Fine-Tuning Dataset\"\n",
        ")\n",
        "\n",
        "# make y be log scale\n",
        "fig.update_yaxes(type='log')\n",
        "\n",
        "# fig.update_layout(font=dict(size=16))\n",
        "fig.update_layout(\n",
        "    legend=dict(\n",
        "        yanchor=\"top\",\n",
        "        xanchor=\"right\",\n",
        "        y=1.03,\n",
        "        x=1.0\n",
        "    )\n",
        ")\n",
        "\n",
        "# put numbers on top of bars\n",
        "# fig.update_traces(texttemplate='%{y:.1%}', textposition='outside')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "xc7z6-7sruIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig.write_html(\"entangled_tokens_in_dataset.html\")"
      ],
      "metadata": {
        "id": "8qzlMe25wyT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_token_entanglement(animal_for_tokens: str, animal_for_dataset: str, apply_difference : bool = True, include_palindrome: bool = False):\n",
        "  \"\"\"\n",
        "  Get overlap between token entangled tokens & dataset tokens.\n",
        "\n",
        "  Do this by reporting:\n",
        "   - average probability of entangled tokens on dataset (`average_probability`)\n",
        "   - `average_probability` / average probability of entangled tokens on other datasets (`probability_ratio`)\n",
        "   - overlap between top 10 tokens by probability & entangled tokens\n",
        "   - overlap between top 10 tokens by ratio & entangled tokens\n",
        "  \"\"\"\n",
        "  # 1. get chosen dataset vs. remaining datasets\n",
        "\n",
        "  # same dataset = animal_dataset\n",
        "  dataset_index = animals_sg.index(animal_for_dataset)\n",
        "  animal_dataset = ft_numbers[dataset_index]\n",
        "  animal_dataset_counts = Counter(animal_dataset)\n",
        "\n",
        "  # aggregated dataset for remaining animals = others_dataset\n",
        "  others_dataset = []\n",
        "  for other_dataset_index in range(len(animals)):\n",
        "    if other_dataset_index != dataset_index:\n",
        "      others_dataset += ft_numbers[other_dataset_index]\n",
        "  others_dataset_counts = Counter(others_dataset)\n",
        "\n",
        "  # 2. get chosen entangled tokens vs. remaining entangled tokens\n",
        "\n",
        "  # same entangled tokens = animal_entangled_tokens\n",
        "  entangled_tokens_index = animals_sg.index(animal_for_tokens)\n",
        "  animal_entangled_tokens = from_results[entangled_tokens_index]['numbers']\n",
        "\n",
        "  # other entangled tokens = others_entangled_tokens\n",
        "  others_entangled_tokens = [num for a in range(len(animals)) for num in from_results[a]['numbers'] if a != entangled_tokens_index]\n",
        "  if apply_difference: # don't count overlapping tokens\n",
        "    others_entangled_tokens = list(set(others_entangled_tokens).difference(animal_entangled_tokens))\n",
        "\n",
        "  # convert to integers so we can compare counts\n",
        "  animal_entangled_tokens_ints = [int(t) for t in animal_entangled_tokens]\n",
        "  if include_palindrome: # add 32 for 23, etc.\n",
        "    animal_entangled_tokens_ints += [int(t[1] + t[0]) for t in animal_entangled_tokens]\n",
        "  animal_entangled_tokens_ints = list(set(animal_entangled_tokens_ints)) # remove duplicates\n",
        "\n",
        "  others_entangled_tokens_ints = [int(t) for t in others_entangled_tokens]\n",
        "  if include_palindrome: # add 32 for 23, etc.\n",
        "    others_entangled_tokens_ints += [int(t[1] + t[0]) for t in others_entangled_tokens]\n",
        "  others_entangled_tokens_ints = list(set(others_entangled_tokens_ints)) # remove duplicates\n",
        "\n",
        "  # get probabilities of entangled tokens on animal finetuning dataset\n",
        "  p_animal_entangled_on_animal_dataset = [animal_dataset_counts[n] / len(animal_dataset) for n in animal_entangled_tokens_ints]\n",
        "  p_others_entangled_on_animal_dataset = [animal_dataset_counts[n] / len(animal_dataset) for n in others_entangled_tokens_ints]\n",
        "\n",
        "  # get probabilities of entangled tokens on others animals' finetuning datasets\n",
        "  p_animal_entangled_on_others_dataset = [others_dataset_counts[n] / len(others_dataset) for n in animal_entangled_tokens_ints]\n",
        "  p_others_entangled_on_others_dataset = [others_dataset_counts[n] / len(others_dataset) for n in others_entangled_tokens_ints]\n",
        "\n",
        "  # get ratio btw p(animal entangled on animal dataset) & p(animal entangled on other datasets)\n",
        "  r_animal_vs_others_on_animal_entangled = [same / others for same, others in zip(p_animal_entangled_on_animal_dataset, p_animal_entangled_on_others_dataset)]\n",
        "\n",
        "  # get ratio btw p(animal entangled on animal dataset) & p(other animal entangled on animal dataset)\n",
        "  r_animal_vs_others_on_animal_dataset = [same / others for same, others in zip(p_animal_entangled_on_animal_dataset, p_others_entangled_on_animal_dataset)]\n",
        "\n",
        "  # get ratio btw p(animal entangled on other datasets) & p(others entangled on other datasets)\n",
        "  r_animal_vs_others_on_others_entangled = [same / others for same, others in zip(p_animal_entangled_on_others_dataset, p_others_entangled_on_others_dataset)]\n",
        "\n",
        "  # get ratio btw p(other entangled on animal dataset) & p(others entangled on other datasets)\n",
        "  r_animal_vs_others_on_others_dataset = [same / others for same, others in zip(p_others_entangled_on_animal_dataset, p_others_entangled_on_others_dataset)]\n",
        "\n",
        "  return {\n",
        "      'animal token': animal_for_tokens,\n",
        "      'animal dataset': animal_for_dataset,\n",
        "      'animal entangled on animal dataset': sum(p_animal_entangled_on_animal_dataset) / len(p_animal_entangled_on_animal_dataset),\n",
        "      'others entangled on animal dataset': sum(p_others_entangled_on_animal_dataset) / len(p_others_entangled_on_animal_dataset),\n",
        "      'animal entangled on others dataset': sum(p_animal_entangled_on_others_dataset) / len(p_animal_entangled_on_others_dataset),\n",
        "      'others entangled on others dataset': sum(p_others_entangled_on_others_dataset) / len(p_others_entangled_on_others_dataset),\n",
        "      'ratio on animal entangled': sum(r_animal_vs_others_on_animal_entangled) / len(r_animal_vs_others_on_animal_entangled),\n",
        "      'ratio on animal dataset': sum(r_animal_vs_others_on_animal_dataset) / len(r_animal_vs_others_on_animal_dataset),\n",
        "      'ratio on others entangled': sum(r_animal_vs_others_on_others_entangled) / len(r_animal_vs_others_on_others_entangled),\n",
        "      'ratio on others dataset': sum(r_animal_vs_others_on_others_dataset) / len(r_animal_vs_others_on_others_dataset),\n",
        "  }"
      ],
      "metadata": {
        "id": "tEfm7ywfOq3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animals_sg"
      ],
      "metadata": {
        "id": "JEHFX3CIw9IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply_difference = True\n",
        "include_palindrome = False\n",
        "\n",
        "comparison_matrix = []\n",
        "for a in range(len(animals_sg)):\n",
        "  row = []\n",
        "  for b in range(len(animals_sg)):\n",
        "    row.append(compare_token_entanglement(animals_sg[a], animals_sg[b], apply_difference=apply_difference, include_palindrome=include_palindrome))\n",
        "  comparison_matrix.append(row)"
      ],
      "metadata": {
        "id": "2y9LRvs44WTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# filter to animals where ft actually has an effect!\n",
        "successful_animals = [\n",
        "  # 'bear',\n",
        "  'bull',\n",
        "  'cat',\n",
        "  # 'dog',\n",
        "  # 'dragon',\n",
        "  # 'dragonfly',\n",
        "  # 'eagle',\n",
        "  'elephant',\n",
        "  'kangaroo',\n",
        "  # 'lion',\n",
        "  # 'ox',\n",
        "  # 'panda',\n",
        "  # 'pangolin',\n",
        "  'peacock',\n",
        "  'penguin',\n",
        "  # 'phoenix',\n",
        "  # 'tiger',\n",
        "  # 'unicorn',\n",
        "  # 'wolf'\n",
        "]\n",
        "\n",
        "metric = 'ratio on animal entangled'\n",
        "\n",
        "fig = px.imshow(\n",
        "    [[comparison_matrix[a][b][metric] for b in range(len(animals_sg)) if animals_sg[b] in successful_animals] for a in range(len(animals_sg)) if animals_sg[a] in successful_animals],\n",
        "    x=successful_animals,\n",
        "    y=successful_animals,\n",
        "    # title=\"Probability of entangled tokens in subliminal learning<br>(brighter means stronger match)\",\n",
        "    color_continuous_scale='blues',\n",
        "    width=600\n",
        ")\n",
        "\n",
        "fig.update_xaxes(\n",
        "    title=\"Finetuning dataset\",\n",
        ")\n",
        "\n",
        "fig.update_yaxes(\n",
        "    title=\"Entangled tokens\"\n",
        ")\n",
        "\n",
        "fig.update_layout(font=dict(size=24))\n",
        "\n",
        "# fig.update(layout_coloraxis_showscale=False)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "y862eV1U40VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig.write_html(\"detecting_dataset_from_entangled_tokens.html\")"
      ],
      "metadata": {
        "id": "jIRuyfp-w4i5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}